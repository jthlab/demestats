from dataclasses import dataclass
from functools import partial, reduce

import diffrax as dfx
import equinox as eqx
import jax
import jax.numpy as jnp
import numpy as np
from beartype import beartype
from beartype.typing import Callable, NamedTuple
from jaxtyping import Array, Float, Scalar, ScalarLike
from loguru import logger

import demesinfer.events as base
import demesinfer.util as util
from demesinfer.path import Path, get_path

NoOp = base.NoOp
Epoch = base.Epoch

SetupState = None


class State(NamedTuple):
    # p is an (d,)*n  array denoting the joint probability that each of N lineages is
    # in each of D demes.
    # c is the probability that the first coalescence event has not occured by time t.
    p: Float[Array, "..."]  # (d+1,)*n
    pops: tuple[str]
    log_s: Float[Array, ""]

    def check_shape(self):
        assert p.shape[0] == 1 + len(self.pops)


StateReturn = tuple[State, dict]
SetupReturn = tuple[SetupState, dict]


def setup_lift(
    state: None, t0: Path, t1: Path, terminal: bool, aux: dict, demo: dict
) -> tuple[None, dict]:
    return None, dict(migrations=list(util.migrations_in(demo, t0, t1)))


def lift(
    state: State, t0: Path, t1: Path, terminal: bool, demo: dict, aux: dict
) -> StateReturn:
    """Lift partial likelihood.

    Args:
        state: state just before the lifting event
        t0: time before the lifting event
        t1: time after the lifting event
        terminal: does lift go to infinity?
        demo: dict of parameters
        aux: dict of auxiliary data generated by setup

    Returns:
        State after the lifting event.
    """
    logger.debug("lift: state={} t0={} t1={} terminal={}", state, t0, t1, terminal)
    t0 = jnp.array(get_path(demo, t0))
    t1 = jnp.array(get_path(demo, t1))

    n = state.p.ndim
    d = len(state.pops)
    assert state.p.shape == (d + 1,) * n, (
        f"Expected shape {(d + 1,) * n}, got {state.p.shape}"
    )
    inds = np.transpose(np.unravel_index(np.arange((d + 1) ** n), (d + 1,) * n))
    counts = jax.vmap(lambda b: jnp.bincount(b, length=d + 1))(inds).reshape(
        (d + 1,) * n + (d + 1,)
    )
    C = counts * (counts - 1) / 2
    mu = partial(util.migration_rate, demo)
    etas = util.coalescent_rates(demo)
    active_migr = [m for m in aux["migrations"] if set(m) & set(state.pops)]

    if len(active_migr) == 0 or terminal:

        def f(t, state=state):
            R = []
            for p in state.pops:
                R.append(etas[p].R(t) - etas[p].R(t0))
            # no coalescence allowed in the "untracked" deme
            R.append(0.0)
            R = jnp.array(R)
            log_p_prime = jnp.log(state.p) - C.dot(R)
            log_s_prime = jax.scipy.special.logsumexp(log_p_prime)
            p_prime = jnp.exp(log_p_prime - log_s_prime)
            coal = jnp.array([1 / 2 / etas[p](t) for p in state.pops])
            coal = jnp.append(coal, 0.0)
            # probability distribution conditional on no coalescence
            c = jnp.sum(p_prime * C.dot(coal))
            return dict(c=c, log_s=state.log_s + log_s_prime, p=p_prime)

        d1 = f(t1)
        state = state._replace(log_s=d1["log_s"], p=d1["p"])
        return state, {"lift": f, "t0": t0, "t1": t1}

    return _lift_migration(state, t0, t1, terminal, demo, aux, etas, mu, C)


def _lift_migration(
    state: State,
    t0: ScalarLike,
    t1: ScalarLike,
    terminal: bool,
    demo: dict,
    aux: dict,
    etas: dict[str, Callable],
    mu: Callable,
    C: Float[Array, "..."],
) -> StateReturn:
    """Lift partial likelihood.

    Args:
        st: state just before the lifting event
        demo: dict of parameters
        aux: dict of auxiliary data generated by setup

    Returns:
        State after the lifting event.
    """
    aux = aux or {}
    n = state.p.ndim

    def rate(t):
        eta = jnp.array([1 / 2 / etas[pop](t) for pop in state.pops])
        eta = jnp.append(eta, 0.0)
        return C.dot(eta)

    def f(t, y, args):
        # migration matrix at time t
        # etas, C = args
        M_t = jnp.array(
            [[mu(dest, src, t) for dest in state.pops] for src in state.pops]
        )
        M_t = jnp.pad(M_t, ((0, 1), (0, 1)), constant_values=0.0)  # add untracked deme
        M_t = M_t - jnp.diag(M_t.sum(axis=1))  # make it a stochastic matrix
        # transition p forward in time
        p, s = y
        ds = p * rate(t)
        # multiply along each axis, equivalent of direct sum
        dp = sum(
            map(
                lambda i: jnp.apply_along_axis(M_t.T.__matmul__, i, p),
                range(n),
            )
        )
        # movement into coalescent state
        dp -= ds  # movement among migrant states, independent
        return dp, ds.sum()

    solver = dfx.Kvaerno3()
    term = dfx.ODETerm(f)
    eta_ts = jnp.concatenate([eta.t[:-1] for eta in etas.values()])
    mu_ts = jnp.array(
        [m.get(x, t0) for m in demo["migrations"] for x in ("start_time", "end_time")]
    )
    jump_ts = jnp.concatenate([eta_ts, mu_ts])
    jump_ts = jnp.sort(jump_ts)
    saveat = dfx.SaveAt(dense=True, t1=True)
    # FIXME using jump_ts causes nans to be returned
    ssc = dfx.PIDController(rtol=1e-6, atol=1e-6, jump_ts=jump_ts)
    args = (etas, C)
    y0 = (state.p, 0.0)

    # if f has error, this will throw more comprehensibly than doing it inside of diffeqsolve
    y1 = f(t0, y0, args)
    sol = dfx.diffeqsolve(
        term,
        solver,
        t0=t0,
        t1=t1,
        dt0=(t1 - t0) / 100.0,
        args=args,
        y0=y0,
        stepsize_controller=ssc,
        max_steps=4096,
        saveat=saveat,
    )
    p1 = sol.ys[0][0]
    s1 = sol.ys[1][0]
    p1 = p1 / p1.sum()  # normalize to probability conditional on non-coalescence

    def f(t, state=state):
        y = sol.evaluate(t)
        p, s = y
        p /= p.sum()
        c = jnp.sum(p * rate(t))
        return dict(c=c, log_s=state.log_s + jnp.log1p(-s), p=p)

    state = state._replace(
        p=p1,
        log_s=state.log_s + jnp.log1p(-s1),
    )

    return state, {"lift": f, "t0": t0, "t1": t1}


@dataclass(kw_only=True)
class PopulationStart(base.PopulationStart):
    pass


@dataclass(kw_only=True)
class Split1(base.Split1):
    def __call__(self, demo: dict, aux: dict, child_state: State) -> StateReturn:
        pops = child_state.pops
        assert self.donor in pops
        assert self.recipient in pops
        lst = list(pops)
        j = lst.index(self.donor)
        lst.pop(j)  # remove the donor from the axes
        k = lst.index(self.recipient)
        pops = tuple(lst)
        p_prime = _merge(child_state.p, j, k)
        return child_state._replace(pops=pops, p=p_prime), {}


@dataclass(kw_only=True)
class Split2(base.Split2):
    def __call__(
        self, demo: dict, aux: dict, donor_state: State, recipient_state: State
    ) -> StateReturn:
        """Merge two populations in different event blocks.

        Args:
            st: state just before the merge event
            demo: dict of parameters
            aux: dict of auxiliary data generated by setup
        """
        p_prime = _product(recipient_state.p, donor_state.p)
        # now want to merge the populations in donor and recip into one
        combined_pops = recipient_state.pops + donor_state.pops
        j, k = [list(combined_pops).index(x) for x in (self.donor, self.recipient)]
        p_prime = _merge(p_prime, j, k)
        cp = list(combined_pops)
        cp.remove(self.donor)
        return State(
            p=p_prime,
            pops=tuple(cp),
            log_s=donor_state.log_s + recipient_state.log_s,
        ), {}


@dataclass(kw_only=True)
class Merge(base.Merge):
    def __call__(
        self, demo: dict, aux: dict, pop1_state: State, pop2_state
    ) -> StateReturn:
        # merge the two population tensors into one
        # an empty/scalar tensor represents one deme with no lineages
        p_prime = _product(pop1_state.p, pop2_state.p)
        return State(
            p=p_prime,
            pops=pop1_state.pops + pop2_state.pops,
            log_s=pop1_state.log_s + pop2_state.log_s,
        ), {}


@dataclass(kw_only=True)
class MigrationStart(base.MigrationStart):
    def __call__(self, demo: dict, aux: dict, child_state: State) -> StateReturn:
        return child_state, {}


@dataclass(kw_only=True)
class MigrationEnd(base.MigrationEnd):
    def __call__(self, demo: dict, aux: dict, child_state: State) -> StateReturn:
        return child_state, {}


@dataclass(kw_only=True)
class Admix(base.Admix):
    def __call__(self, demo: dict, aux: dict, child_state: State) -> StateReturn:
        p_admix = self.prop_fun(demo)
        # child splits into self.parent1 and self.parent2
        pops = list(child_state.pops)
        i = pops.index(self.child)
        pops.pop(i)
        pops.extend([self.parent1, self.parent2])
        n = len(pops)
        p_prime = _split(child_state.p, i, n - 2, n - 1, p_admix)
        return child_state._replace(p=p_prime, pops=tuple(pops)), {}


@dataclass(kw_only=True)
class Pulse(base.Pulse):
    def __call__(self, demo: dict, aux: dict, child_state) -> StateReturn:
        p_pulse = self.prop_fun(demo)
        pops = list(child_state.pops)
        i = pops.index(self.dest)
        j = pops.index(self.source)
        p_prime = _pulse(child_state.p, i, j, p_pulse)
        return child_state._replace(p=p_prime), {}


def _merge(p, j, k):
    "merge population j into population k"

    # this means merge tensor indices j into k along each axis
    def f(q, i):
        def g(v):
            return jnp.delete(v, j).at[k].add(v[j])

        return jnp.apply_along_axis(g, i, q)

    return reduce(f, range(p.ndim), p)


def _split(p, j, k1, k2, prob):
    "split population j into populations k1 and k2"
    if k1 > k2:
        return _split(p, j, k2, k1, 1 - prob)

    def f(q, i):
        def g(v):
            vj = v[j]
            v = jnp.delete(v, j)
            v = jnp.insert(v, k1, vj * prob)
            v = jnp.insert(v, k2, vj * (1 - prob))
            return v

        return jnp.apply_along_axis(g, i, q)

    ret = reduce(f, range(p.ndim), p)
    return ret


def _pulse(p, j, k, prob):
    "pulse population j into population k"

    def f(q, i):
        def g(v):
            return v.at[j].multiply(1 - prob).at[k].add(v[j] * prob)

        return jnp.apply_along_axis(g, i, q)

    return reduce(f, range(p.ndim), p)


def _product(p1, p2):
    # align two ndarrays for concatenation
    n = p1.ndim
    assert n == p2.ndim
    d1 = p1.shape[0] - 1
    assert p1.shape == (d1 + 1,) * n
    d2 = p2.shape[0] - 1
    assert p2.shape == (d2 + 1,) * n
    # ret = jnp.zeros((d1 + d2 + 1,) * n)
    inds = jnp.array(jnp.meshgrid(*[jnp.arange(d1 + d2 + 1)] * n, indexing="ij"))
    i1 = jnp.where(inds < d1, inds, -1)
    i2 = jnp.where((d1 <= inds) & (inds < d1 + d2), inds - d1, -1)
    p1f = p1[*i1]
    p2f = p2[*i2]
    return (p1f * p2f).reshape((d1 + d2 + 1,) * n)
