{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3739f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "\n",
    "demo = msp.Demography()\n",
    "demo.add_population(initial_size = 5000, name = \"anc\")\n",
    "demo.add_population(initial_size = 5000, name = \"P0\")\n",
    "demo.add_population(initial_size = 5000, name = \"P1\")\n",
    "demo.add_population(initial_size = 5000, name = \"P2\")\n",
    "demo.add_population(initial_size = 5000, name = \"P3\")\n",
    "demo.add_population(initial_size = 5000, name = \"P4\")\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P1\", \"P2\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P2\", \"P3\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P3\", \"P4\"), rate=0.001)\n",
    "tmp = [f\"P{i}\" for i in range(5)]\n",
    "demo.add_population_split(time = 1000, derived=tmp, ancestral=\"anc\")\n",
    "g = demo.to_demes()\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(5)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)\n",
    "\n",
    "demesdraw.tubes(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c686911",
   "metadata": {},
   "source": [
    "## The next chunk is just the fit function pasted in a code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import msprime as msp\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "import jax.random as jr\n",
    "from jax import vmap, lax \n",
    "\n",
    "from demesinfer.coal_rate import PiecewiseConstant\n",
    "from demesinfer.constr import EventTree, constraints_for\n",
    "from demesinfer.iicr import IICRCurve\n",
    "from demesinfer.loglik.arg import loglik\n",
    "\n",
    "Path = Tuple[Any, ...]\n",
    "Var = Path | Set[Path]\n",
    "Params = Mapping[Var, float]\n",
    "\n",
    "def _dict_to_vec(d: Params, keys: Sequence[Var]) -> jnp.ndarray:\n",
    "    return jnp.asarray([d[k] for k in keys], dtype=jnp.float64)\n",
    "\n",
    "def _vec_to_dict_jax(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, jnp.ndarray]:\n",
    "    return {k: v[i] for i, k in enumerate(keys)}\n",
    "\n",
    "def _vec_to_dict(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, float]:\n",
    "    return {k: float(v[i]) for i, k in enumerate(keys)}\n",
    "\n",
    "def compile(ts, subkey):\n",
    "    # using a set to pull out all unique populations that the samples can possibly belong to\n",
    "    pop_cfg = {ts.population(ts.node(n).population).metadata[\"name\"] for n in ts.samples()}\n",
    "    pop_cfg = {pop_name: 0 for pop_name in pop_cfg}\n",
    "\n",
    "    samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "    a, b = samples[0].item(0), samples[1].item(0)\n",
    "    spans = []\n",
    "    curr_t = None\n",
    "    curr_L = 0.0\n",
    "    for tree in ts.trees():\n",
    "        L = tree.interval.right - tree.interval.left\n",
    "        t = tree.tmrca(a, b)\n",
    "        if curr_t is None or t != curr_t:\n",
    "            if curr_t is not None:\n",
    "                spans.append([curr_t, curr_L])\n",
    "            curr_t = t\n",
    "            curr_L = L\n",
    "        else:\n",
    "            curr_L += L\n",
    "    spans.append([curr_t, curr_L])\n",
    "    data = jnp.asarray(spans, dtype=jnp.float64)\n",
    "    pop_cfg[ts.population(ts.node(a).population).metadata[\"name\"]] += 1\n",
    "    pop_cfg[ts.population(ts.node(b).population).metadata[\"name\"]] += 1\n",
    "    return data, pop_cfg\n",
    "\n",
    "def get_tmrca_data(ts, key, num_samples):\n",
    "    data_list = []\n",
    "    cfg_list = []\n",
    "    max_indices = []\n",
    "    for i in range(num_samples):\n",
    "        key, subkey = jr.split(key)\n",
    "        data, cfg = compile(ts, subkey)\n",
    "        data_list.append(data)\n",
    "        cfg_list.append(cfg)\n",
    "        max_indices.append(data.shape[0] - 1)\n",
    "\n",
    "    lens = jnp.array([d.shape[0] for d in data_list], dtype=jnp.int32)\n",
    "    Lmax = int(lens.max())\n",
    "    Npairs = len(data_list)\n",
    "    data_pad = jnp.full((Npairs, Lmax, 2), jnp.array([1.0, 0.0]), dtype=jnp.float64)\n",
    "\n",
    "    for i, d in enumerate(data_list):\n",
    "        data_pad = data_pad.at[i, : d.shape[0], :].set(d)\n",
    "\n",
    "    deme_names = cfg_list[0].keys()\n",
    "    D = len(deme_names)\n",
    "    cfg_mat = jnp.zeros((num_samples, D), dtype=jnp.int32)\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        for j, n in enumerate(deme_names):\n",
    "            cfg_mat = cfg_mat.at[i, j].set(cfg.get(n, 0))\n",
    "    \n",
    "    return data_pad, cfg_mat, deme_names, jnp.array(max_indices)\n",
    "\n",
    "def plot_likelihood(demo, ts, paths, vec_values, recombination_rate=1e-8, seed=1, num_samples=20, t_min=1e-8, num_t=1000, k=2):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    key = jr.PRNGKey(seed)\n",
    "    path_order: List[Var] = list(paths)\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data, max_index):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data, max_index)\n",
    "    \n",
    "    def evaluate_at_vec(vec):\n",
    "        vec_array = jnp.atleast_1d(vec)\n",
    "        # Batched over cfg_mat and all_tmrca_spans \n",
    "        batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(vec_array, cfg_mat, data_pad, max_indices)\n",
    "        return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "    # Outer vmap: Parallelize across vec_values\n",
    "    # batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "    # # 3. Compute all values (runs on GPU/TPU if available)\n",
    "    # results = batched_neg_loglik(vec_values) \n",
    "    results = lax.map(evaluate_at_vec, vec_values)\n",
    "\n",
    "    # 4. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(vec_values, results, 'r-', linewidth=2)\n",
    "    plt.xlabel(\"vec value\")\n",
    "    plt.ylabel(\"Negative Log-Likelihood\")\n",
    "    plt.title(\"Likelihood Landscape\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return results\n",
    "\n",
    "def fit(\n",
    "    demo,\n",
    "    paths: Params,\n",
    "    ts,\n",
    "    *,\n",
    "    k: int = 2,\n",
    "    n_samples: int = 10,\n",
    "    t_min: float = 1e-8,\n",
    "    # t_max: float,\n",
    "    num_t: int = 1000,\n",
    "    method: str = \"trust-constr\",\n",
    "    options: Optional[dict] = None,\n",
    "    recombination_rate: float = 1e-8,\n",
    "    sequence_length: float = 1e7,\n",
    "    mutation_rate: float = 1e-8,\n",
    "    seed: int = 1,\n",
    "    num_samples = 20,\n",
    "):\n",
    "    key = jr.PRNGKey(seed)\n",
    "    # msp_demo = msp.Demography.from_demes(demo)\n",
    "    # deme_names = [d.name for d in demo.demes]\n",
    "    # samples = {d: n_samples for d in deme_names[1:]}\n",
    "    # ts = msp.sim_mutations(\n",
    "    #     msp.sim_ancestry(\n",
    "    #         samples=samples,\n",
    "    #         demography=msp_demo,\n",
    "    #         recombination_rate=recombination_rate,\n",
    "    #         sequence_length=sequence_length,\n",
    "    #         random_seed=seed,\n",
    "    #     ),\n",
    "    #     rate=mutation_rate,\n",
    "    #     random_seed=seed + 1,\n",
    "    # )\n",
    "\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "\n",
    "    path_order: List[Var] = list(paths)\n",
    "    x0 = _dict_to_vec(paths, path_order)\n",
    "    et = EventTree(demo)\n",
    "\n",
    "    cons = constraints_for(et, *path_order)\n",
    "    linear_constraints: list[LinearConstraint] = []\n",
    "\n",
    "    Aeq, beq = cons[\"eq\"]\n",
    "    if Aeq.size:\n",
    "        linear_constraints.append(LinearConstraint(Aeq, beq, beq))\n",
    "\n",
    "    G, h = cons[\"ineq\"]\n",
    "    if G.size:\n",
    "        lower = -jnp.inf * jnp.ones_like(h)\n",
    "        linear_constraints.append(LinearConstraint(G, lower, h))\n",
    "\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data)\n",
    "    \n",
    "    @jax.value_and_grad\n",
    "    def neg_loglik(vec):\n",
    "        vec = vec\n",
    "        batched_loglik = vmap(\n",
    "        compute_loglik,\n",
    "        in_axes=(None, 0, 0))(vec, cfg_mat, data_pad)\n",
    "        \n",
    "        likelihood = jnp.sum(batched_loglik)\n",
    "\n",
    "        return -likelihood / num_samples\n",
    "\n",
    "    res = minimize(\n",
    "        fun=lambda x: float(neg_loglik(x)[0]),\n",
    "        # fun=lambda x: float(neg_loglik(x)),\n",
    "        x0=jnp.asarray(x0),\n",
    "        jac=lambda x: jnp.asarray(neg_loglik(x)[1], dtype=float),\n",
    "        method=method,\n",
    "        # bounds = [(3000. / 5000., 7000. / 5000.)],\n",
    "        constraints=linear_constraints,\n",
    "    )\n",
    "\n",
    "    return _vec_to_dict(jnp.asarray(res.x), path_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7eca74",
   "metadata": {},
   "source": [
    "## Here's how I would call on plot_likelihood over a vector of values to plot the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "paths = {\n",
    "    frozenset({\n",
    "        ('demes', 1, 'epochs', 0, 'end_size'),\n",
    "        ('demes', 1, 'epochs', 0, 'start_size'),\n",
    "    }): 4000.,\n",
    "}\n",
    "vec_values = jnp.linspace(4000, 7000, 10)\n",
    "result = plot_likelihood(g, ts, paths, vec_values, num_samples = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d9ab0",
   "metadata": {},
   "source": [
    "## Here's how I know it takes way too long to evaluate the likelihood for a *single* parameter value while averaging over 150 samples with 1000 time discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df491025",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(1)\n",
    "num_samples=150\n",
    "path_order: List[Var] = list(paths)\n",
    "data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples=num_samples)\n",
    "first_columns = data_pad[:, :, 0]\n",
    "# Compute global max (single float value)\n",
    "global_max = jnp.max(first_columns)\n",
    "t_breaks = jnp.linspace(1e-8, global_max * 2, 1000)\n",
    "rho = 1e-8\n",
    "iicr = IICRCurve(demo=g, k=2)\n",
    "iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "def compute_loglik(vec, sample_config, data, max_index):\n",
    "    # Convert sample_config (array) to dictionary of population sizes\n",
    "    ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "    \n",
    "    # Initialize params (assuming fixed for all samples)\n",
    "    params = _vec_to_dict_jax(vec, path_order)\n",
    "    \n",
    "    # Compute IICR and log-likelihood\n",
    "    c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "    eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "    return loglik(eta, rho, data, max_index)\n",
    "\n",
    "def evaluate_at_vec(vec):\n",
    "    vec_array = jnp.atleast_1d(vec)\n",
    "    # Batched over cfg_mat and all_tmrca_spans \n",
    "    batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(vec_array, cfg_mat, data_pad, max_indices)\n",
    "    return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "# Outer vmap: Parallelize across vec_values\n",
    "# batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "# # 3. Compute all values (runs on GPU/TPU if available)\n",
    "# results = batched_neg_loglik(vec_values)\n",
    "# vec_values = jnp.linspace(4000, 7000, 10) \n",
    "results = evaluate_at_vec(4000.)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
