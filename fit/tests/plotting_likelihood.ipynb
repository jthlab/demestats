{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3739f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "\n",
    "demo = msp.Demography()\n",
    "demo.add_population(initial_size = 5000, name = \"anc\")\n",
    "demo.add_population(initial_size = 5000, name = \"P0\")\n",
    "demo.add_population(initial_size = 5000, name = \"P1\")\n",
    "demo.add_population(initial_size = 5000, name = \"P2\")\n",
    "demo.add_population(initial_size = 5000, name = \"P3\")\n",
    "demo.add_population(initial_size = 5000, name = \"P4\")\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P1\", \"P2\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P2\", \"P3\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P3\", \"P4\"), rate=0.001)\n",
    "tmp = [f\"P{i}\" for i in range(5)]\n",
    "demo.add_population_split(time = 1000, derived=tmp, ancestral=\"anc\")\n",
    "g = demo.to_demes()\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(5)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)\n",
    "\n",
    "demesdraw.tubes(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c686911",
   "metadata": {},
   "source": [
    "## The next chunk is just the fit function pasted in a code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import msprime as msp\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "import jax.random as jr\n",
    "from jax import vmap, lax \n",
    "\n",
    "from demesinfer.coal_rate import PiecewiseConstant\n",
    "from demesinfer.constr import EventTree, constraints_for\n",
    "from demesinfer.iicr import IICRCurve\n",
    "from demesinfer.loglik.arg import loglik\n",
    "\n",
    "Path = Tuple[Any, ...]\n",
    "Var = Path | Set[Path]\n",
    "Params = Mapping[Var, float]\n",
    "\n",
    "def _dict_to_vec(d: Params, keys: Sequence[Var]) -> jnp.ndarray:\n",
    "    return jnp.asarray([d[k] for k in keys], dtype=jnp.float64)\n",
    "\n",
    "def _vec_to_dict_jax(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, jnp.ndarray]:\n",
    "    return {k: v[i] for i, k in enumerate(keys)}\n",
    "\n",
    "def _vec_to_dict(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, float]:\n",
    "    return {k: float(v[i]) for i, k in enumerate(keys)}\n",
    "\n",
    "def compile(ts, subkey):\n",
    "    # using a set to pull out all unique populations that the samples can possibly belong to\n",
    "    pop_cfg = {ts.population(ts.node(n).population).metadata[\"name\"] for n in ts.samples()}\n",
    "    pop_cfg = {pop_name: 0 for pop_name in pop_cfg}\n",
    "\n",
    "    samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "    a, b = samples[0].item(0), samples[1].item(0)\n",
    "    spans = []\n",
    "    curr_t = None\n",
    "    curr_L = 0.0\n",
    "    for tree in ts.trees():\n",
    "        L = tree.interval.right - tree.interval.left\n",
    "        t = tree.tmrca(a, b)\n",
    "        if curr_t is None or t != curr_t:\n",
    "            if curr_t is not None:\n",
    "                spans.append([curr_t, curr_L])\n",
    "            curr_t = t\n",
    "            curr_L = L\n",
    "        else:\n",
    "            curr_L += L\n",
    "    spans.append([curr_t, curr_L])\n",
    "    data = jnp.asarray(spans, dtype=jnp.float64)\n",
    "    pop_cfg[ts.population(ts.node(a).population).metadata[\"name\"]] += 1\n",
    "    pop_cfg[ts.population(ts.node(b).population).metadata[\"name\"]] += 1\n",
    "    return data, pop_cfg\n",
    "\n",
    "def get_tmrca_data(ts, key, num_samples):\n",
    "    data_list = []\n",
    "    cfg_list = []\n",
    "    max_indices = []\n",
    "    for i in range(num_samples):\n",
    "        key, subkey = jr.split(key)\n",
    "        data, cfg = compile(ts, subkey)\n",
    "        data_list.append(data)\n",
    "        cfg_list.append(cfg)\n",
    "        max_indices.append(data.shape[0] - 1)\n",
    "\n",
    "    lens = jnp.array([d.shape[0] for d in data_list], dtype=jnp.int32)\n",
    "    Lmax = int(lens.max())\n",
    "    Npairs = len(data_list)\n",
    "    data_pad = jnp.full((Npairs, Lmax, 2), jnp.array([1.0, 0.0]), dtype=jnp.float64)\n",
    "\n",
    "    for i, d in enumerate(data_list):\n",
    "        data_pad = data_pad.at[i, : d.shape[0], :].set(d)\n",
    "\n",
    "    deme_names = cfg_list[0].keys()\n",
    "    D = len(deme_names)\n",
    "    cfg_mat = jnp.zeros((num_samples, D), dtype=jnp.int32)\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        for j, n in enumerate(deme_names):\n",
    "            cfg_mat = cfg_mat.at[i, j].set(cfg.get(n, 0))\n",
    "    \n",
    "    return data_pad, cfg_mat, deme_names, jnp.array(max_indices)\n",
    "\n",
    "def plot_likelihood(demo, ts, paths, vec_values, recombination_rate=1e-8, seed=1, num_samples=20, t_min=1e-8, num_t=1000, k=2):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    key = jr.PRNGKey(seed)\n",
    "    path_order: List[Var] = list(paths)\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data, max_index):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data, max_index)\n",
    "    \n",
    "    def evaluate_at_vec(vec):\n",
    "        vec_array = jnp.atleast_1d(vec)\n",
    "        # Batched over cfg_mat and all_tmrca_spans \n",
    "        batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(vec_array, cfg_mat, data_pad, max_indices)\n",
    "        return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "    # Outer vmap: Parallelize across vec_values\n",
    "    # batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "    # # 3. Compute all values (runs on GPU/TPU if available)\n",
    "    # results = batched_neg_loglik(vec_values) \n",
    "    results = lax.map(evaluate_at_vec, vec_values)\n",
    "\n",
    "    # 4. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(vec_values, results, 'r-', linewidth=2)\n",
    "    plt.xlabel(\"vec value\")\n",
    "    plt.ylabel(\"Negative Log-Likelihood\")\n",
    "    plt.title(\"Likelihood Landscape\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return results\n",
    "\n",
    "def fit(\n",
    "    demo,\n",
    "    paths: Params,\n",
    "    ts,\n",
    "    *,\n",
    "    k: int = 2,\n",
    "    n_samples: int = 10,\n",
    "    t_min: float = 1e-8,\n",
    "    # t_max: float,\n",
    "    num_t: int = 1000,\n",
    "    method: str = \"trust-constr\",\n",
    "    options: Optional[dict] = None,\n",
    "    recombination_rate: float = 1e-8,\n",
    "    sequence_length: float = 1e7,\n",
    "    mutation_rate: float = 1e-8,\n",
    "    seed: int = 1,\n",
    "    num_samples = 20,\n",
    "):\n",
    "    key = jr.PRNGKey(seed)\n",
    "    # msp_demo = msp.Demography.from_demes(demo)\n",
    "    # deme_names = [d.name for d in demo.demes]\n",
    "    # samples = {d: n_samples for d in deme_names[1:]}\n",
    "    # ts = msp.sim_mutations(\n",
    "    #     msp.sim_ancestry(\n",
    "    #         samples=samples,\n",
    "    #         demography=msp_demo,\n",
    "    #         recombination_rate=recombination_rate,\n",
    "    #         sequence_length=sequence_length,\n",
    "    #         random_seed=seed,\n",
    "    #     ),\n",
    "    #     rate=mutation_rate,\n",
    "    #     random_seed=seed + 1,\n",
    "    # )\n",
    "\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "\n",
    "    path_order: List[Var] = list(paths)\n",
    "    x0 = _dict_to_vec(paths, path_order)\n",
    "    et = EventTree(demo)\n",
    "\n",
    "    cons = constraints_for(et, *path_order)\n",
    "    linear_constraints: list[LinearConstraint] = []\n",
    "\n",
    "    Aeq, beq = cons[\"eq\"]\n",
    "    if Aeq.size:\n",
    "        linear_constraints.append(LinearConstraint(Aeq, beq, beq))\n",
    "\n",
    "    G, h = cons[\"ineq\"]\n",
    "    if G.size:\n",
    "        lower = -jnp.inf * jnp.ones_like(h)\n",
    "        linear_constraints.append(LinearConstraint(G, lower, h))\n",
    "\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data)\n",
    "    \n",
    "    @jax.value_and_grad\n",
    "    def neg_loglik(vec):\n",
    "        vec = vec\n",
    "        batched_loglik = vmap(\n",
    "        compute_loglik,\n",
    "        in_axes=(None, 0, 0))(vec, cfg_mat, data_pad)\n",
    "        \n",
    "        likelihood = jnp.sum(batched_loglik)\n",
    "\n",
    "        return -likelihood / num_samples\n",
    "\n",
    "    res = minimize(\n",
    "        fun=lambda x: float(neg_loglik(x)[0]),\n",
    "        # fun=lambda x: float(neg_loglik(x)),\n",
    "        x0=jnp.asarray(x0),\n",
    "        jac=lambda x: jnp.asarray(neg_loglik(x)[1], dtype=float),\n",
    "        method=method,\n",
    "        # bounds = [(3000. / 5000., 7000. / 5000.)],\n",
    "        constraints=linear_constraints,\n",
    "    )\n",
    "\n",
    "    return _vec_to_dict(jnp.asarray(res.x), path_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7eca74",
   "metadata": {},
   "source": [
    "## Here's how I would call on plot_likelihood over a vector of values to plot the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "paths = {\n",
    "    frozenset({\n",
    "        ('demes', 1, 'epochs', 0, 'end_size'),\n",
    "        ('demes', 1, 'epochs', 0, 'start_size'),\n",
    "    }): 4000.,\n",
    "}\n",
    "vec_values = jnp.linspace(4000, 7000, 10)\n",
    "result = plot_likelihood(g, ts, paths, vec_values, num_samples = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d9ab0",
   "metadata": {},
   "source": [
    "## Here's how I know it takes way too long to evaluate the likelihood for a *single* parameter value while averaging over 150 samples with 1000 time discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df491025",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(1)\n",
    "num_samples=150\n",
    "path_order: List[Var] = list(paths)\n",
    "data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples=num_samples)\n",
    "first_columns = data_pad[:, :, 0]\n",
    "# Compute global max (single float value)\n",
    "global_max = jnp.max(first_columns)\n",
    "t_breaks = jnp.linspace(1e-8, global_max * 2, 1000)\n",
    "rho = 1e-8\n",
    "iicr = IICRCurve(demo=g, k=2)\n",
    "iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "def compute_loglik(vec, sample_config, data, max_index):\n",
    "    # Convert sample_config (array) to dictionary of population sizes\n",
    "    ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "    \n",
    "    # Initialize params (assuming fixed for all samples)\n",
    "    params = _vec_to_dict_jax(vec, path_order)\n",
    "    \n",
    "    # Compute IICR and log-likelihood\n",
    "    c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "    eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "    return loglik(eta, rho, data, max_index)\n",
    "\n",
    "def evaluate_at_vec(vec):\n",
    "    vec_array = jnp.atleast_1d(vec)\n",
    "    # Batched over cfg_mat and all_tmrca_spans \n",
    "    batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(vec_array, cfg_mat, data_pad, max_indices)\n",
    "    return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "# Outer vmap: Parallelize across vec_values\n",
    "# batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "# # 3. Compute all values (runs on GPU/TPU if available)\n",
    "# results = batched_neg_loglik(vec_values)\n",
    "# vec_values = jnp.linspace(4000, 7000, 10) \n",
    "results = evaluate_at_vec(4000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd4830",
   "metadata": {},
   "source": [
    "## NaNs in eta bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "\n",
    "# Create demography object\n",
    "demo = msp.Demography()\n",
    "\n",
    "# Add populations\n",
    "demo.add_population(initial_size=3000, name=\"anc\")\n",
    "demo.add_population(initial_size=1000, name=\"P0\")\n",
    "demo.add_population(initial_size=1000, name=\"P1\")\n",
    "\n",
    "# Set initial migration rate\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.0001)\n",
    "\n",
    "# population growth at 500 generations\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P0\"\n",
    ")\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P1\"\n",
    ")\n",
    "\n",
    "# Migration rate change changed to 0.001 AFTER 500 generation (going into the past)\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P0\",\n",
    "    dest=\"P1\"\n",
    ")\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P1\",\n",
    "    dest=\"P0\"\n",
    ")\n",
    "\n",
    "# THEN add the older events (population split at 1000)\n",
    "demo.add_population_split(time=1000, derived=[\"P0\", \"P1\"], ancestral=\"anc\")\n",
    "\n",
    "# Visualize the demography\n",
    "g = demo.to_demes()\n",
    "demesdraw.tubes(g)\n",
    "\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(2)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e8, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2fa7f",
   "metadata": {},
   "source": [
    "## copy pasting fit function into next code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ebd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example implementation of a fit function for parameter inference.\n",
    "# This is intended for tutorial use only. We do not take responsibility for any bugs or issues in this code.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import msprime as msp\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "import jax.random as jr\n",
    "from jax import vmap, lax \n",
    "\n",
    "from demesinfer.coal_rate import PiecewiseConstant\n",
    "from demesinfer.constr import EventTree, constraints_for\n",
    "from demesinfer.iicr import IICRCurve\n",
    "from demesinfer.loglik.arg import loglik\n",
    "\n",
    "Path = Tuple[Any, ...]\n",
    "Var = Path | Set[Path]\n",
    "Params = Mapping[Var, float]\n",
    "\n",
    "def _dict_to_vec(d: Params, keys: Sequence[Var]) -> jnp.ndarray:\n",
    "    return jnp.asarray([d[k] for k in keys], dtype=jnp.float64)\n",
    "\n",
    "def _vec_to_dict_jax(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, jnp.ndarray]:\n",
    "    return {k: v[i] for i, k in enumerate(keys)}\n",
    "\n",
    "def _vec_to_dict(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, float]:\n",
    "    return {k: float(v[i]) for i, k in enumerate(keys)}\n",
    "\n",
    "def compile(ts, subkey):\n",
    "    # using a set to pull out all unique populations that the samples can possibly belong to\n",
    "    pop_cfg = {ts.population(ts.node(n).population).metadata[\"name\"] for n in ts.samples()}\n",
    "    pop_cfg = {pop_name: 0 for pop_name in pop_cfg}\n",
    "\n",
    "    samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "    a, b = samples[0].item(0), samples[1].item(0)\n",
    "    spans = []\n",
    "    curr_t = None\n",
    "    curr_L = 0.0\n",
    "    for tree in ts.trees():\n",
    "        L = tree.interval.right - tree.interval.left\n",
    "        t = tree.tmrca(a, b)\n",
    "        if curr_t is None or t != curr_t:\n",
    "            if curr_t is not None:\n",
    "                spans.append([curr_t, curr_L])\n",
    "            curr_t = t\n",
    "            curr_L = L\n",
    "        else:\n",
    "            curr_L += L\n",
    "    spans.append([curr_t, curr_L])\n",
    "    data = jnp.asarray(spans, dtype=jnp.float64)\n",
    "    pop_cfg[ts.population(ts.node(a).population).metadata[\"name\"]] += 1\n",
    "    pop_cfg[ts.population(ts.node(b).population).metadata[\"name\"]] += 1\n",
    "    return data, pop_cfg\n",
    "\n",
    "def get_tmrca_data(ts, key, num_samples):\n",
    "    data_list = []\n",
    "    cfg_list = []\n",
    "    max_indices = []\n",
    "    for i in range(num_samples):\n",
    "        key, subkey = jr.split(key)\n",
    "        data, cfg = compile(ts, subkey)\n",
    "        data_list.append(data)\n",
    "        cfg_list.append(cfg)\n",
    "        max_indices.append(data.shape[0] - 1)\n",
    "\n",
    "    lens = jnp.array([d.shape[0] for d in data_list], dtype=jnp.int32)\n",
    "    Lmax = int(lens.max())\n",
    "    Npairs = len(data_list)\n",
    "    data_pad = jnp.full((Npairs, Lmax, 2), jnp.array([1.0, 0.0]), dtype=jnp.float64)\n",
    "\n",
    "    for i, d in enumerate(data_list):\n",
    "        data_pad = data_pad.at[i, : d.shape[0], :].set(d)\n",
    "\n",
    "    deme_names = cfg_list[0].keys()\n",
    "    D = len(deme_names)\n",
    "    cfg_mat = jnp.zeros((num_samples, D), dtype=jnp.int32)\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        for j, n in enumerate(deme_names):\n",
    "            cfg_mat = cfg_mat.at[i, j].set(cfg.get(n, 0))\n",
    "\n",
    "    unique_cfg = jnp.unique(cfg_mat, axis=0)\n",
    "\n",
    "    # Find matching indices\n",
    "    def find_matching_index(row, unique_arrays):\n",
    "        matches = jnp.all(row == unique_arrays, axis=1)\n",
    "        return jnp.where(matches)[0][0]\n",
    "\n",
    "    # Vectorize over all rows in `arr`\n",
    "    matching_indices = jnp.array([find_matching_index(row, unique_cfg) for row in cfg_mat])\n",
    "    \n",
    "    return data_pad, cfg_mat, deme_names, jnp.array(max_indices), unique_cfg, matching_indices\n",
    "\n",
    "def plot_likelihood(demo, ts, paths, vec_values, recombination_rate=1e-8, seed=1, num_samples=20, t_min=1e-8, num_t=1000, k=2):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    key = jr.PRNGKey(seed)\n",
    "    path_order: List[Var] = list(paths)\n",
    "    data_pad, cfg_mat, deme_names, max_indices, unique_cfg, matching_indices = get_tmrca_data(ts, key, num_samples)\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    print(global_max)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(c_map, c_index, data, max_index):\n",
    "        c = c_map[c_index]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data, max_index)\n",
    "    \n",
    "    def evaluate_at_vec(vec):\n",
    "        vec_array = jnp.atleast_1d(vec)\n",
    "        params = _vec_to_dict_jax(vec_array, path_order)\n",
    "\n",
    "        def compute_c(sample_config):\n",
    "            # Convert sample_config (array) to dictionary of population sizes\n",
    "            ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "            \n",
    "            # Compute IICR and log-likelihood\n",
    "            c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "            return c\n",
    "        c_map = vmap(compute_c, in_axes=(0))(unique_cfg)\n",
    "        # c_map = jax.vmap(lambda cfg: iicr_call(params=params, t=t_breaks, num_samples=dict(zip(deme_names, cfg)))[\"c\"])(\n",
    "        #     jnp.array(unique_cfg)\n",
    "        # )\n",
    "        \n",
    "        # Batched over cfg_mat and all_tmrca_spans \n",
    "        batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(c_map, matching_indices, data_pad, max_indices)\n",
    "        return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "    # Outer vmap: Parallelize across vec_values\n",
    "    batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "    # 3. Compute all values (runs on GPU/TPU if available)\n",
    "    results = batched_neg_loglik(vec_values) \n",
    "    # results = lax.map(evaluate_at_vec, vec_values)\n",
    "\n",
    "    # 4. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(vec_values, results, 'r-', linewidth=2)\n",
    "    plt.xlabel(\"vec value\")\n",
    "    plt.ylabel(\"Negative Log-Likelihood\")\n",
    "    plt.title(\"Likelihood Landscape\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return results\n",
    "\n",
    "def fit(\n",
    "    demo,\n",
    "    paths: Params,\n",
    "    ts,\n",
    "    *,\n",
    "    k: int = 2,\n",
    "    n_samples: int = 10,\n",
    "    t_min: float = 1e-8,\n",
    "    # t_max: float,\n",
    "    num_t: int = 1000,\n",
    "    method: str = \"trust-constr\",\n",
    "    options: Optional[dict] = None,\n",
    "    recombination_rate: float = 1e-8,\n",
    "    sequence_length: float = 1e7,\n",
    "    mutation_rate: float = 1e-8,\n",
    "    seed: int = 1,\n",
    "    num_samples = 20,\n",
    "):\n",
    "    key = jr.PRNGKey(seed)\n",
    "    # msp_demo = msp.Demography.from_demes(demo)\n",
    "    # deme_names = [d.name for d in demo.demes]\n",
    "    # samples = {d: n_samples for d in deme_names[1:]}\n",
    "    # ts = msp.sim_mutations(\n",
    "    #     msp.sim_ancestry(\n",
    "    #         samples=samples,\n",
    "    #         demography=msp_demo,\n",
    "    #         recombination_rate=recombination_rate,\n",
    "    #         sequence_length=sequence_length,\n",
    "    #         random_seed=seed,\n",
    "    #     ),\n",
    "    #     rate=mutation_rate,\n",
    "    #     random_seed=seed + 1,\n",
    "    # )\n",
    "\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "\n",
    "    path_order: List[Var] = list(paths)\n",
    "    x0 = _dict_to_vec(paths, path_order)\n",
    "    et = EventTree(demo)\n",
    "\n",
    "    cons = constraints_for(et, *path_order)\n",
    "    linear_constraints: list[LinearConstraint] = []\n",
    "\n",
    "    Aeq, beq = cons[\"eq\"]\n",
    "    if Aeq.size:\n",
    "        linear_constraints.append(LinearConstraint(Aeq, beq, beq))\n",
    "\n",
    "    G, h = cons[\"ineq\"]\n",
    "    if G.size:\n",
    "        lower = -jnp.inf * jnp.ones_like(h)\n",
    "        linear_constraints.append(LinearConstraint(G, lower, h))\n",
    "\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data)\n",
    "    \n",
    "    @jax.value_and_grad\n",
    "    def neg_loglik(vec):\n",
    "        vec = vec\n",
    "        batched_loglik = vmap(\n",
    "        compute_loglik,\n",
    "        in_axes=(None, 0, 0))(vec, cfg_mat, data_pad)\n",
    "        \n",
    "        likelihood = jnp.sum(batched_loglik)\n",
    "\n",
    "        return -likelihood / num_samples\n",
    "\n",
    "    res = minimize(\n",
    "        fun=lambda x: float(neg_loglik(x)[0]),\n",
    "        # fun=lambda x: float(neg_loglik(x)),\n",
    "        x0=jnp.asarray(x0),\n",
    "        jac=lambda x: jnp.asarray(neg_loglik(x)[1], dtype=float),\n",
    "        method=method,\n",
    "        # bounds = [(3000. / 5000., 7000. / 5000.)],\n",
    "        constraints=linear_constraints,\n",
    "    )\n",
    "\n",
    "    return _vec_to_dict(jnp.asarray(res.x), path_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14446361",
   "metadata": {},
   "source": [
    "## Here is the NaN error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f80c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "paths = {\n",
    "    frozenset({('demes', 2, 'start_time'), ('demes', 0, 'epochs', 0, 'end_time'), ('demes', 1, 'start_time'), ('migrations', 0, 'start_time'), ('migrations', 1, 'start_time')}): 2000.,\n",
    "}\n",
    "vec_values = jnp.linspace(500, 1500, 20)\n",
    "\n",
    "key = jr.PRNGKey(1)\n",
    "path_order: List[Var] = list(paths)\n",
    "data_pad, cfg_mat, deme_names, max_indices, unique_cfg, matching_indices = get_tmrca_data(ts, key, num_samples=5)\n",
    "first_columns = data_pad[:, :, 0]\n",
    "# Compute global max (single float value)\n",
    "global_max = jnp.max(first_columns)\n",
    "print(global_max)\n",
    "t_breaks = jnp.linspace(1e-8, global_max * 2, 1000)\n",
    "rho = 1e-8\n",
    "iicr = IICRCurve(demo=g, k=2)\n",
    "iicr_call = jax.jit(iicr.__call__)\n",
    "params = _vec_to_dict_jax(jnp.array([vec_values[0]]), path_order)\n",
    "i = 0\n",
    "data = data_pad[i]\n",
    "sample_config = cfg_mat[i]\n",
    "max_index = max_indices[i]\n",
    "# Convert sample_config (array) to dictionary of population sizes\n",
    "ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "\n",
    "# Compute IICR and log-likelihood\n",
    "c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "loglik(eta, rho, data, max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f1efd",
   "metadata": {},
   "source": [
    "## Here is the params type error, the iicr can be called on with frozenset in the dictionary but esfs cannot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48082a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "import demes\n",
    "from demesinfer.sfs import ExpectedSFS\n",
    "\n",
    "demo = msp.Demography()\n",
    "demo.add_population(initial_size = 5000, name = \"anc\")\n",
    "demo.add_population(initial_size = 5000, name = \"P0\")\n",
    "demo.add_population(initial_size = 5000, name = \"P1\")\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.001)\n",
    "tmp = [f\"P{i}\" for i in range(2)]\n",
    "demo.add_population_split(time = 1000, derived=tmp, ancestral=\"anc\")\n",
    "g = demo.to_demes()\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(2)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)\n",
    "\n",
    "samples = {f\"P{i}\": 20 for i in range(2)}\n",
    "esfs = ExpectedSFS(g, num_samples=samples)\n",
    "# e1 = esfs(params = {('migrations', 0, 'rate'): 0.005} )\n",
    "e1 = esfs(params = {frozenset({\n",
    "        ('demes', 0, 'epochs', 0, 'end_size'),\n",
    "        ('demes', 0, 'epochs', 0, 'start_size'),\n",
    "    }): 7000.} )\n",
    "afs = ts.allele_frequency_spectrum(sample_sets=[ts.samples([1]), ts.samples([2])], span_normalise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5271b59",
   "metadata": {},
   "source": [
    "## Phlashlib Error where the loglik does not evaluate for the case where sequence length > warmup length\n",
    "# Please note: many of these variables are related to the actual simulation, I just threw in random numbers for theta and rho to get loglik running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564566ee",
   "metadata": {},
   "source": [
    "first two code chunks are for constructing the demography and necessary data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "import numpy as np\n",
    "\n",
    "# Create demography object\n",
    "demo = msp.Demography()\n",
    "\n",
    "# Add populations\n",
    "demo.add_population(initial_size=3000, name=\"anc\")\n",
    "demo.add_population(initial_size=500, name=\"P0\", growth_rate=-np.log(3000 / 500)/500)\n",
    "demo.add_population(initial_size=100, name=\"P1\", growth_rate=-np.log(3000 / 100)/500)\n",
    "\n",
    "# # Add exponential decline for P0 starting 1000 generations ago\n",
    "# decline_time = 1000  # When decline starts (generations ago)\n",
    "# initial_size = 5000  # Size at decline_time\n",
    "# final_size = 1000    # Size at present (time 0) - smaller population\n",
    "\n",
    "# # Calculate negative growth rate for decline\n",
    "# growth_rate = np.log(final_size / initial_size) / decline_time\n",
    "# print(f\"Growth rate: {growth_rate:.6f}\")  # Will be negative\n",
    "\n",
    "# Set initial migration rate\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.0001)\n",
    "\n",
    "# population growth at 500 generations\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P0\",\n",
    "    growth_rate=0\n",
    ")\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P1\",\n",
    "    growth_rate=0\n",
    ")\n",
    "\n",
    "# Migration rate change changed to 0.001 AFTER 500 generation (going into the past)\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P0\",\n",
    "    dest=\"P1\"\n",
    ")\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P1\",\n",
    "    dest=\"P0\"\n",
    ")\n",
    "\n",
    "# THEN add the older events (population split at 1000)\n",
    "demo.add_population_split(time=1000, derived=[\"P0\", \"P1\"], ancestral=\"anc\")\n",
    "\n",
    "# Visualize the demography\n",
    "g = demo.to_demes()\n",
    "demesdraw.tubes(g)\n",
    "\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(2)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c65949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import msprime as msp\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "import jax.random as jr\n",
    "from jax import vmap, lax \n",
    "\n",
    "from demesinfer.coal_rate import PiecewiseConstant\n",
    "from demesinfer.constr import EventTree, constraints_for\n",
    "from demesinfer.iicr import IICRCurve\n",
    "from demesinfer.loglik.arg import loglik\n",
    "from jax.scipy.special import xlogy\n",
    "from demesinfer.sfs import ExpectedSFS\n",
    "\n",
    "Path = Tuple[Any, ...]\n",
    "Var = Path | Set[Path]\n",
    "Params = Mapping[Var, float]\n",
    "\n",
    "def _dict_to_vec(d: Params, keys: Sequence[Var]) -> jnp.ndarray:\n",
    "    return jnp.asarray([d[k] for k in keys], dtype=jnp.float64)\n",
    "\n",
    "def _vec_to_dict_jax(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, jnp.ndarray]:\n",
    "    return {k: v[i] for i, k in enumerate(keys)}\n",
    "\n",
    "def _vec_to_dict(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, float]:\n",
    "    return {k: float(v[i]) for i, k in enumerate(keys)}\n",
    "\n",
    "from intervaltree import IntervalTree\n",
    "import tqdm.auto as tqdm\n",
    "import tskit\n",
    "\n",
    "def _read_ts(\n",
    "    ts: tskit.TreeSequence,\n",
    "    nodes: list[tuple[int, int]],\n",
    "    window_size: int,\n",
    "    progress: bool = False,\n",
    ") -> np.ndarray:\n",
    "    nodes_flat = list({x for t in nodes for x in t})\n",
    "    node_inds = np.array([[nodes_flat.index(x) for x in t] for t in nodes])\n",
    "    N = len(nodes)\n",
    "    L = int(np.ceil(ts.get_sequence_length() / window_size))\n",
    "    G = np.zeros([N, L], dtype=np.int8)\n",
    "    with tqdm.tqdm(\n",
    "        ts.variants(samples=nodes_flat, copy=False),\n",
    "        total=ts.num_sites,\n",
    "        disable=not progress,\n",
    "    ) as pbar:\n",
    "        pbar.set_description(\"Reading tree sequence\")\n",
    "        for v in pbar:\n",
    "            g = v.genotypes[node_inds]\n",
    "            ell = int(v.position / window_size)\n",
    "            G[:, ell] += g[:, 0] != g[:, 1]\n",
    "    return G\n",
    "\n",
    "def get_data(ts, nodes=None, window_size=100, mask=None):\n",
    "    # form interval tree for masking\n",
    "    L = int(ts.get_sequence_length())\n",
    "    mask = mask or []\n",
    "    \n",
    "    if nodes is None:\n",
    "        nodes = [tuple(i.nodes) for i in ts.individuals()]\n",
    "\n",
    "    tr = IntervalTree.from_tuples([(0, L)])\n",
    "    for a, b in mask:\n",
    "        tr.chop(a, b)\n",
    "    # compute breakpoints\n",
    "    bp = np.array([x for i in tr for x in [i.begin, i.end]])\n",
    "    assert len(set(bp)) == len(bp)\n",
    "    assert (bp == np.sort(bp)).all()\n",
    "    if bp[0] != 0.0:\n",
    "        bp = np.insert(bp, 0, 0.0)\n",
    "    if bp[-1] != L:\n",
    "        bp = np.append(bp, L)\n",
    "    mid = (bp[:-1] + bp[1:]) / 2.0\n",
    "    unmasked = [bool(tr[m]) for m in mid]\n",
    "    nodes_flat = list({x for t in nodes for x in t})\n",
    "    afs = ts.allele_frequency_spectrum(\n",
    "        sample_sets=[nodes_flat], windows=bp, polarised=True, span_normalise=False\n",
    "    )[unmasked].sum(0)[1:-1]\n",
    "    het_matrix = _read_ts(ts, nodes, window_size)\n",
    "    # now mask out columns of the het matrix based on interval\n",
    "    # overlap\n",
    "    tr = IntervalTree.from_tuples(mask)\n",
    "    column_mask = [\n",
    "        bool(tr[a : a + window_size]) for a in range(0, L, window_size)\n",
    "    ]\n",
    "    assert len(column_mask) == het_matrix.shape[1]\n",
    "    # set mask out these columns\n",
    "    het_matrix[:, column_mask] = -1\n",
    "    return dict(afs=afs, het_matrix=het_matrix)\n",
    "\n",
    "def compile(ts, subkey, a=None, b=None):\n",
    "    # using a set to pull out all unique populations that the samples can possibly belong to\n",
    "    pop_cfg = {ts.population(ts.node(n).population).metadata[\"name\"] for n in ts.samples()}\n",
    "    pop_cfg = {pop_name: 0 for pop_name in pop_cfg}\n",
    "\n",
    "    if a == None and b == None:\n",
    "        samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "        a, b = samples[0].item(0), samples[1].item(0)\n",
    "\n",
    "    pop_cfg[ts.population(ts.node(a).population).metadata[\"name\"]] += 1\n",
    "    pop_cfg[ts.population(ts.node(b).population).metadata[\"name\"]] += 1\n",
    "    return pop_cfg, (a, b)\n",
    "\n",
    "def get_het_data(ts, key=jax.random.PRNGKey(2), num_samples=200, option=\"random\", window_size=100, mask=None):\n",
    "    cfg_list = []\n",
    "    all_config=[]\n",
    "    key, subkey = jr.split(key)\n",
    "    if option == \"random\":\n",
    "        for i in range(num_samples):\n",
    "            cfg, pair = compile(ts, subkey)\n",
    "            cfg_list.append(cfg)\n",
    "            all_config.append(pair)\n",
    "            key, subkey = jr.split(key)\n",
    "    elif option == \"all\":\n",
    "        from itertools import combinations\n",
    "        all_config = list(combinations(ts.samples(), 2))\n",
    "        for a, b in all_config:\n",
    "            cfg = compile(ts, subkey, a, b)\n",
    "            cfg_list.append(cfg)\n",
    "    elif option == \"unphased\":\n",
    "        all_config = ts.samples().reshape(-1, 2)\n",
    "        for a, b in all_config:\n",
    "            cfg = compile(ts, subkey, a, b)\n",
    "            cfg_list.append(cfg)\n",
    "\n",
    "    result = get_data(ts, all_config, window_size, mask)\n",
    "    return result, cfg_list\n",
    "\n",
    "def process_data(cfg_list):\n",
    "    num_samples = len(cfg_list)\n",
    "\n",
    "    deme_names = cfg_list[0].keys()\n",
    "    D = len(deme_names)\n",
    "    cfg_mat = jnp.zeros((num_samples, D), dtype=jnp.int32)\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        for j, n in enumerate(deme_names):\n",
    "            cfg_mat = cfg_mat.at[i, j].set(cfg.get(n, 0))\n",
    "\n",
    "    unique_cfg = jnp.unique(cfg_mat, axis=0)\n",
    "\n",
    "    # Find matching indices\n",
    "    def find_matching_index(row, unique_arrays):\n",
    "        matches = jnp.all(row == unique_arrays, axis=1)\n",
    "        return jnp.where(matches)[0][0]\n",
    "\n",
    "    # Vectorize over all rows in `arr`\n",
    "    matching_indices = jnp.array([find_matching_index(row, unique_cfg) for row in cfg_mat])\n",
    "    \n",
    "    return cfg_mat, deme_names, unique_cfg, matching_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55022e2",
   "metadata": {},
   "source": [
    "here is my chunked het_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d306266",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, cfg_list = get_het_data(ts)\n",
    "het_matrix = result[\"het_matrix\"]\n",
    "print(het_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ebb3c",
   "metadata": {},
   "source": [
    "This code below only works because the length of the data you pass in is less than length of warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077962e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phlashlib.iicr import PiecewiseConstant\n",
    "from phlashlib.loglik import loglik\n",
    "import jax.numpy as jnp\n",
    "t = jnp.array([0.0, 1.0, 2.0, 3.0])\n",
    "c = jnp.array([0.001, 0.001, 0.011])\n",
    "iicr = PiecewiseConstant(t=t[:-1], c=c)\n",
    "ll = loglik(jnp.array(het_matrix[1][1:100]), iicr, t, theta=1.0, rho=1.0)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe93fde",
   "metadata": {},
   "source": [
    "Now the error happens when sequence length is 1e7 > warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68dde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phlashlib.iicr import PiecewiseConstant\n",
    "from phlashlib.loglik import loglik\n",
    "import jax.numpy as jnp\n",
    "t = jnp.array([0.0, 1.0, 2.0, 3.0])\n",
    "c = jnp.array([0.001, 0.001, 0.001])\n",
    "iicr = PiecewiseConstant(t=t[:-1], c=c)\n",
    "ll = loglik(jnp.array(het_matrix[1]), iicr, t, theta=1.0, rho=1.0)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a128e2",
   "metadata": {},
   "source": [
    "## Phlashlib lax.map Error\n",
    "First chunk is for running the simulation and loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f81490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "import numpy as np\n",
    "\n",
    "# Create demography object\n",
    "demo = msp.Demography()\n",
    "\n",
    "# Add populations\n",
    "demo.add_population(initial_size=3000, name=\"anc\")\n",
    "demo.add_population(initial_size=500, name=\"P0\", growth_rate=-np.log(3000 / 500)/500)\n",
    "demo.add_population(initial_size=100, name=\"P1\", growth_rate=-np.log(3000 / 100)/500)\n",
    "\n",
    "# # Add exponential decline for P0 starting 1000 generations ago\n",
    "# decline_time = 1000  # When decline starts (generations ago)\n",
    "# initial_size = 5000  # Size at decline_time\n",
    "# final_size = 1000    # Size at present (time 0) - smaller population\n",
    "\n",
    "# # Calculate negative growth rate for decline\n",
    "# growth_rate = np.log(final_size / initial_size) / decline_time\n",
    "# print(f\"Growth rate: {growth_rate:.6f}\")  # Will be negative\n",
    "\n",
    "# Set initial migration rate\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.0001)\n",
    "\n",
    "# population growth at 500 generations\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P0\",\n",
    "    growth_rate=0\n",
    ")\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P1\",\n",
    "    growth_rate=0\n",
    ")\n",
    "\n",
    "# Migration rate change changed to 0.001 AFTER 500 generation (going into the past)\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P0\",\n",
    "    dest=\"P1\"\n",
    ")\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P1\",\n",
    "    dest=\"P0\"\n",
    ")\n",
    "\n",
    "# THEN add the older events (population split at 1000)\n",
    "demo.add_population_split(time=1000, derived=[\"P0\", \"P1\"], ancestral=\"anc\")\n",
    "\n",
    "# Visualize the demography\n",
    "g = demo.to_demes()\n",
    "demesdraw.tubes(g)\n",
    "\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(2)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import msprime as msp\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "import jax.random as jr\n",
    "from jax import vmap, lax \n",
    "\n",
    "from demesinfer.constr import EventTree, constraints_for\n",
    "from demesinfer.iicr import IICRCurve\n",
    "from phlashlib.loglik import loglik\n",
    "from phlashlib.iicr import PiecewiseConstant\n",
    "from jax.scipy.special import xlogy\n",
    "from demesinfer.sfs import ExpectedSFS\n",
    "\n",
    "Path = Tuple[Any, ...]\n",
    "Var = Path | Set[Path]\n",
    "Params = Mapping[Var, float]\n",
    "\n",
    "def _dict_to_vec(d: Params, keys: Sequence[Var]) -> jnp.ndarray:\n",
    "    return jnp.asarray([d[k] for k in keys], dtype=jnp.float64)\n",
    "\n",
    "def _vec_to_dict_jax(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, jnp.ndarray]:\n",
    "    return {k: v[i] for i, k in enumerate(keys)}\n",
    "\n",
    "def _vec_to_dict(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, float]:\n",
    "    return {k: float(v[i]) for i, k in enumerate(keys)}\n",
    "\n",
    "from intervaltree import IntervalTree\n",
    "import tqdm.auto as tqdm\n",
    "import tskit\n",
    "\n",
    "def _read_ts(\n",
    "    ts: tskit.TreeSequence,\n",
    "    nodes: list[tuple[int, int]],\n",
    "    window_size: int,\n",
    "    progress: bool = False,\n",
    ") -> np.ndarray:\n",
    "    nodes_flat = list({x for t in nodes for x in t})\n",
    "    node_inds = np.array([[nodes_flat.index(x) for x in t] for t in nodes])\n",
    "    N = len(nodes)\n",
    "    L = int(np.ceil(ts.get_sequence_length() / window_size))\n",
    "    G = np.zeros([N, L], dtype=np.int8)\n",
    "    with tqdm.tqdm(\n",
    "        ts.variants(samples=nodes_flat, copy=False),\n",
    "        total=ts.num_sites,\n",
    "        disable=not progress,\n",
    "    ) as pbar:\n",
    "        pbar.set_description(\"Reading tree sequence\")\n",
    "        for v in pbar:\n",
    "            g = v.genotypes[node_inds]\n",
    "            ell = int(v.position / window_size)\n",
    "            G[:, ell] += g[:, 0] != g[:, 1]\n",
    "    return G\n",
    "\n",
    "def get_data(ts, nodes=None, window_size=100, mask=None):\n",
    "    # form interval tree for masking\n",
    "    L = int(ts.get_sequence_length())\n",
    "    mask = mask or []\n",
    "    \n",
    "    if nodes is None:\n",
    "        nodes = [tuple(i.nodes) for i in ts.individuals()]\n",
    "\n",
    "    tr = IntervalTree.from_tuples([(0, L)])\n",
    "    for a, b in mask:\n",
    "        tr.chop(a, b)\n",
    "    # compute breakpoints\n",
    "    bp = np.array([x for i in tr for x in [i.begin, i.end]])\n",
    "    assert len(set(bp)) == len(bp)\n",
    "    assert (bp == np.sort(bp)).all()\n",
    "    if bp[0] != 0.0:\n",
    "        bp = np.insert(bp, 0, 0.0)\n",
    "    if bp[-1] != L:\n",
    "        bp = np.append(bp, L)\n",
    "    mid = (bp[:-1] + bp[1:]) / 2.0\n",
    "    unmasked = [bool(tr[m]) for m in mid]\n",
    "    nodes_flat = list({x for t in nodes for x in t})\n",
    "    afs = ts.allele_frequency_spectrum(\n",
    "        sample_sets=[nodes_flat], windows=bp, polarised=True, span_normalise=False\n",
    "    )[unmasked].sum(0)[1:-1]\n",
    "    het_matrix = _read_ts(ts, nodes, window_size)\n",
    "    # now mask out columns of the het matrix based on interval\n",
    "    # overlap\n",
    "    tr = IntervalTree.from_tuples(mask)\n",
    "    column_mask = [\n",
    "        bool(tr[a : a + window_size]) for a in range(0, L, window_size)\n",
    "    ]\n",
    "    assert len(column_mask) == het_matrix.shape[1]\n",
    "    # set mask out these columns\n",
    "    het_matrix[:, column_mask] = -1\n",
    "    return dict(afs=afs, het_matrix=het_matrix)\n",
    "\n",
    "def compile(ts, subkey, a=None, b=None):\n",
    "    # using a set to pull out all unique populations that the samples can possibly belong to\n",
    "    pop_cfg = {ts.population(ts.node(n).population).metadata[\"name\"] for n in ts.samples()}\n",
    "    pop_cfg = {pop_name: 0 for pop_name in pop_cfg}\n",
    "\n",
    "    if a == None and b == None:\n",
    "        samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "        a, b = samples[0].item(0), samples[1].item(0)\n",
    "\n",
    "    pop_cfg[ts.population(ts.node(a).population).metadata[\"name\"]] += 1\n",
    "    pop_cfg[ts.population(ts.node(b).population).metadata[\"name\"]] += 1\n",
    "    return pop_cfg, (a, b)\n",
    "\n",
    "def get_het_data(ts, key=jax.random.PRNGKey(2), num_samples=10, option=\"random\", window_size=100, mask=None):\n",
    "    cfg_list = []\n",
    "    all_config=[]\n",
    "    key, subkey = jr.split(key)\n",
    "    if option == \"random\":\n",
    "        for i in range(num_samples):\n",
    "            cfg, pair = compile(ts, subkey)\n",
    "            cfg_list.append(cfg)\n",
    "            all_config.append(pair)\n",
    "            key, subkey = jr.split(key)\n",
    "    elif option == \"all\":\n",
    "        from itertools import combinations\n",
    "        all_config = list(combinations(ts.samples(), 2))\n",
    "        for a, b in all_config:\n",
    "            cfg = compile(ts, subkey, a, b)\n",
    "            cfg_list.append(cfg)\n",
    "    elif option == \"unphased\":\n",
    "        all_config = ts.samples().reshape(-1, 2)\n",
    "        for a, b in all_config:\n",
    "            cfg = compile(ts, subkey, a, b)\n",
    "            cfg_list.append(cfg)\n",
    "\n",
    "    result = get_data(ts, all_config, window_size, mask)\n",
    "    return result, cfg_list\n",
    "\n",
    "def process_data(cfg_list):\n",
    "    num_samples = len(cfg_list)\n",
    "\n",
    "    deme_names = cfg_list[0].keys()\n",
    "    D = len(deme_names)\n",
    "    cfg_mat = jnp.zeros((num_samples, D), dtype=jnp.int32)\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        for j, n in enumerate(deme_names):\n",
    "            cfg_mat = cfg_mat.at[i, j].set(cfg.get(n, 0))\n",
    "\n",
    "    unique_cfg = jnp.unique(cfg_mat, axis=0)\n",
    "\n",
    "    # Find matching indices\n",
    "    def find_matching_index(row, unique_arrays):\n",
    "        matches = jnp.all(row == unique_arrays, axis=1)\n",
    "        return jnp.where(matches)[0][0]\n",
    "\n",
    "    # Vectorize over all rows in `arr`\n",
    "    matching_indices = jnp.array([find_matching_index(row, unique_cfg) for row in cfg_mat])\n",
    "    \n",
    "    return cfg_mat, deme_names, unique_cfg, matching_indices\n",
    "\n",
    "def plot_iicr_likelihood(demo, data, cfg_list, paths, vec_values, recombination_rate=1e-8, theta=1e-8, t_min=1e-8, t_max=1e4, num_t=2000, k=2):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    het_matrix = data[\"het_matrix\"]\n",
    "    path_order: List[Var] = list(paths)\n",
    "    cfg_mat, deme_names, unique_cfg, matching_indices = process_data(cfg_list)\n",
    "    num_samples = len(cfg_mat)\n",
    "    t_breaks = jnp.insert(jnp.geomspace(t_min, t_max, 2000), 0, 0.0)\n",
    "    t_iicr = jnp.insert(jnp.geomspace(t_min, t_max, num_t), 0, 0.0)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(c_map, c_index, data):\n",
    "        c = c_map[c_index]\n",
    "        eta = PiecewiseConstant(c=c, t=t_iicr)\n",
    "        return loglik(data, eta, t_breaks, theta, rho)\n",
    "    \n",
    "    def evaluate_at_vec(vec):\n",
    "        vec_array = jnp.atleast_1d(vec)\n",
    "        params = _vec_to_dict_jax(vec_array, path_order)\n",
    "\n",
    "        c_map = jax.vmap(lambda cfg: iicr_call(params=params, t=t_iicr, num_samples=dict(zip(deme_names, cfg)))[\"c\"])(\n",
    "            jnp.array(unique_cfg)\n",
    "        )\n",
    "        \n",
    "        # Batched over cfg_mat and all_tmrca_spans \n",
    "        batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0))(c_map, matching_indices, het_matrix)\n",
    "        return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "    # Outer vmap: Parallelize across vec_values\n",
    "    # batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "    # 3. Compute all values (runs on GPU/TPU if available)\n",
    "    # results = batched_neg_loglik(vec_values) \n",
    "    results = lax.map(evaluate_at_vec, vec_values)\n",
    "\n",
    "    # 4. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(vec_values, results, 'r-', linewidth=2)\n",
    "    plt.xlabel(\"vec value\")\n",
    "    plt.ylabel(\"Negative Log-Likelihood\")\n",
    "    plt.title(\"IICR Likelihood Landscape\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, cfg_list = get_het_data(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e559b0",
   "metadata": {},
   "source": [
    "# everything runs smoothly for vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "recombination_rate=1e-8 * window_size\n",
    "theta=1e-8 * window_size\n",
    "t_min=1e-8\n",
    "t_max=1e4\n",
    "num_t=2000\n",
    "k=2\n",
    "paths = {\n",
    "    frozenset({\n",
    "        ('demes', 0, 'epochs', 0, 'end_size'),\n",
    "        ('demes', 0, 'epochs', 0, 'start_size'),\n",
    "    }): 4000.,\n",
    "}\n",
    "demo = g\n",
    "het_matrix = data[\"het_matrix\"]\n",
    "path_order: List[Var] = list(paths)\n",
    "cfg_mat, deme_names, unique_cfg, matching_indices = process_data(cfg_list)\n",
    "num_samples = len(cfg_mat)\n",
    "t_breaks = jnp.insert(jnp.geomspace(t_min, t_max, 100), 0, 0.0)\n",
    "t_iicr = jnp.insert(jnp.geomspace(t_min, t_max, num_t), 0, 0.0)\n",
    "rho = recombination_rate\n",
    "iicr = IICRCurve(demo=demo, k=k)\n",
    "iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "def compute_loglik(c_map, c_index, data_row):\n",
    "    c = c_map[c_index]\n",
    "    eta = PiecewiseConstant(c=c, t=t_iicr)\n",
    "    return loglik(data_row, eta, t_breaks, theta, rho)\n",
    "    \n",
    "def evaluate_at_vec(vec):\n",
    "    vec_array = jnp.atleast_1d(vec)\n",
    "    params = _vec_to_dict_jax(vec_array, path_order)\n",
    "\n",
    "    c_map = jax.vmap(lambda cfg: iicr_call(params=params, t=t_iicr, num_samples=dict(zip(deme_names, cfg)))[\"c\"])(\n",
    "        jnp.array(unique_cfg)\n",
    "    )\n",
    "    \n",
    "    # Batched over cfg_mat and all_tmrca_spans \n",
    "    batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0))(c_map, matching_indices, het_matrix)\n",
    "    return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "# Outer vmap: Parallelize across vec_values\n",
    "vec_values = jnp.linspace(4000, 7000, 10)\n",
    "batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "results = batched_neg_loglik(vec_values) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b92f5c",
   "metadata": {},
   "source": [
    "# Not so smoothly for lax.map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f561e0e",
   "metadata": {},
   "source": [
    "window_size = 100\n",
    "recombination_rate=1e-8 * window_size\n",
    "theta=1e-8 * window_size\n",
    "t_min=1e-8\n",
    "t_max=1e4\n",
    "num_t=2000\n",
    "k=2\n",
    "paths = {\n",
    "    frozenset({\n",
    "        ('demes', 0, 'epochs', 0, 'end_size'),\n",
    "        ('demes', 0, 'epochs', 0, 'start_size'),\n",
    "    }): 4000.,\n",
    "}\n",
    "demo = g\n",
    "het_matrix = data[\"het_matrix\"]\n",
    "path_order: List[Var] = list(paths)\n",
    "cfg_mat, deme_names, unique_cfg, matching_indices = process_data(cfg_list)\n",
    "num_samples = len(cfg_mat)\n",
    "t_breaks = jnp.insert(jnp.geomspace(t_min, t_max, 100), 0, 0.0)\n",
    "t_iicr = jnp.insert(jnp.geomspace(t_min, t_max, num_t), 0, 0.0)\n",
    "rho = recombination_rate\n",
    "iicr = IICRCurve(demo=demo, k=k)\n",
    "iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "def compute_loglik(c_map, c_index, data_row):\n",
    "    c = c_map[c_index]\n",
    "    eta = PiecewiseConstant(c=c, t=t_iicr)\n",
    "    return loglik(data_row, eta, t_breaks, theta, rho)\n",
    "    \n",
    "def evaluate_at_vec(vec):\n",
    "    vec_array = jnp.atleast_1d(vec)\n",
    "    params = _vec_to_dict_jax(vec_array, path_order)\n",
    "\n",
    "    c_map = jax.vmap(lambda cfg: iicr_call(params=params, t=t_iicr, num_samples=dict(zip(deme_names, cfg)))[\"c\"])(\n",
    "        jnp.array(unique_cfg)\n",
    "    )\n",
    "    \n",
    "    # Batched over cfg_mat and all_tmrca_spans \n",
    "    batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0))(c_map, matching_indices, het_matrix)\n",
    "    return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "# Outer vmap: Parallelize across vec_values\n",
    "vec_values = jnp.linspace(4000, 7000, 10)\n",
    "# batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "# results = batched_neg_loglik(vec_values) \n",
    "results = lax.map(evaluate_at_vec, vec_values)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
