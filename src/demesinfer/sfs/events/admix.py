"""Admixture events."""

from collections import OrderedDict
from copy import deepcopy
from dataclasses import dataclass

import jax
import jax.numpy as jnp
import lineax as lx
import numpy as np
from jaxtyping import Int, ScalarLike
from penzai import pz

import demesinfer.events as base
from demesinfer.util import log_hypergeom

from .state import *


@dataclass(kw_only=True)
class Merge(base.Merge):
    def setup(
        self, demo: dict, aux: dict, pop1_state: SetupState, pop2_state: SetupState
    ) -> SetupReturn:
        mig = pop1_state.migrations | pop2_state.migrations
        axes = pop1_state.axes | pop2_state.axes
        ns = pop1_state.ns
        new_state = SetupState(
            **{
                k: getattr(pop1_state, k) | getattr(pop2_state, k)
                for k in ("migrations", "axes", "ns")
            }
        )
        return new_state, {}

    def __call__(
        self,
        demo: dict,
        aux: dict,
        pop1_state: State,
        pop2_state: State,
    ) -> StateReturn:
        # merge the two population tensors into one
        # pop1_state.pl * pop2_state.pl works because of penzai broadcasting.
        return State(
            pl=pop1_state.pl * pop2_state.pl,
            phi=pop1_state.l0 * pop2_state.phi + pop2_state.l0 * pop1_state.phi,
            l0=pop1_state.l0 * pop2_state.l0,
        ), {}


@dataclass(kw_only=True)
class Pulse(base.Pulse):
    """A pulse of admixture between two populations in the same block.

    Args:
        source: population that donates lineages
        dest: population that receives lineages
        f_p: function that takes pd and returns the admixture proportion.

    Notes:
        See Lemma 2 of Kamm et al. (2020). The assumption that the populations are in the same block is critical.
        Otherwise, we model it is as admixture followed by split.
    """

    def __post_init__(self):
        assert self.source != self.dest

    def setup(self, demo: dict, aux: dict, child_state: SetupState) -> SetupReturn:
        """Compute the combinatorial factors that are constant for all values of p."""
        # admixture works by sampling a fraction p of lineages from the donor population, 1 - p from the other. we model
        # this as a binomial draw, and then use the hypergeometric distribution to compute the probability of the
        # derived allele in the recipient population.
        # consistent with the notation in kamm et al 2020, we write
        aux = {}
        nw1 = child_state.axes[self.dest] - 1
        nw2 = child_state.axes[self.source] - 1
        i, j, k = np.ogrid[: nw1 + nw2 + 1, : nw1 + 1, : nw2 + 1]
        aux = admix_matrices(nw1)
        # this is basically copypasta fram split1. we let oe_einsum figure it all out.
        aux["H3"] = np.exp(log_hypergeom(M=nw1 + nw2, N=i, n=nw1, k=j)) * (
            i == j + k
        )  # [nw1+nw2+1, nw1+1, nw2+1]
        # axis computation
        new_ns = deepcopy(child_state.ns)
        # source is now ancestral to all the populations in the destination, too
        new_ns[self.source].update(new_ns[self.dest])
        # same idea for the out axes
        out_axes = OrderedDict(child_state.axes)
        # the sample size of the source population increases to the size of all subntended
        # leaf populations
        n = sum(new_ns[self.source].values())
        out_axes[self.source] = n + 1
        # downsample if necessary
        assert n <= nw1 + nw2
        if n < nw1 + nw2:
            # replaces the old code, B_plus = jnp.linalg.pinv(B), with QR. this is faster if we call repeatedly,
            # (and probably not slower since I think pinv does a QR anyways.)
            B = np.exp(
                log_hypergeom(
                    M=nw1 + nw2, N=i[..., 0], n=n, k=jnp.arange(n + 1)[None, :]
                )
            )  # [nw1+nw2+1, n + 1]
            # B x = y, where x is the downsampled vector and y is the original vector.
            # i.e. x solves the least squares problem min ||Bx - y||^2
            aux["B"] = B
            aux["Bplus"] = np.linalg.pinv(B, rcond=1e-5)  # [n+1, nw1+nw2+1]
        new_state = child_state._replace(
            axes=out_axes,
            ns=new_ns,
        )
        return new_state, aux

    def __call__(self, demo: dict, aux: dict, child_state: State) -> StateReturn:
        """Pulse admixture when source and donor are in the same block.

        Args:
            st: State just before the admixing event.
            params: dictionary of parameters
            aux: dict of auxiliary data generated by setup function

        Returns:
            Likelihood of the parents just after the admixture event.

        Notes:
            See Lemma 2 of Kamm et al. (2020).
        """
        p = self.prop_fun(demo)
        nw = child_state.pl.named_axes[self.dest] - 1
        xw, j1, m1 = np.ogrid[(slice(None, nw + 1),) * 3]
        B = binom_pmf_safe(m1, nw, p)
        # C[j,k,u] is the probability of drawing u black balls from two urns when the total number of draws
        # from urn 1 is binomial(p) and the total number of black balls in the two urns are j and k respectively.
        C = convolve_sum(aux["H1"] * B, aux["H2"])[..., : nw + 1]
        # C_inds = [b, a, self.dest]
        # H3_inds = [c, b, self.source]

        @pz.nx.nmap
        def f(pl):
            source = 0
            dest = 1
            b = 2
            new_dest = 3
            new_source = 4
            return jnp.einsum(
                pl,
                [source, dest],
                C,
                [b, new_dest, dest],
                aux["H3"],
                [new_source, b, source],
                [new_source, new_dest],
            )

        plp = f(child_state.pl.untag(self.source, self.dest)).tag(
            self.source, self.dest
        )

        if "Bplus" in aux:  # and finally we hypergeom downsample
            # solve B+ X = Y for Y = plp
            B = jnp.asarray(aux["B"])
            op = lx.MatrixLinearOperator(B)

            @pz.nx.nmap
            def f(y):
                sol = lx.linear_solve(
                    op, y, solver=lx.AutoLinearSolver(well_posed=None)
                )
                return sol.value

            plp = f(plp.untag(self.source)).tag(self.source)

        return child_state._replace(pl=plp), {}


@dataclass(kw_only=True)
class Admix(base.Admix):
    """Admixture event.

    Args:
        child: population that is result of admixture
        parent1: first parent population which donates a fraction p of alleles
        parent2: second parent population which donates a fraction 1-p of alleles
    """

    def setup(self, demo: dict, aux: dict, child_state: SetupState) -> SetupReturn:
        """Setup admixture event"""
        out_axes = OrderedDict(child_state.axes)
        n_w = out_axes[self.child] - 1
        # delete the child first. this allows for one of the parents to have the same name as the child
        del out_axes[self.child]
        out_axes[self.parent1] = out_axes[self.parent2] = n_w + 1
        # each parent is now ancestral to the child populations
        nsp = deepcopy(child_state.ns)
        # _important_: delete nsp[child] first, because one of the parents might be the same as the child.
        del nsp[self.child]
        # then it will be re-added here:
        for p in self.parent1, self.parent2:
            nsp.setdefault(p, {})
            nsp[p].update(child_state.ns[self.child])
        # compute hypergeometric sums needed to apply admixture lemma
        aux = admix_matrices(n_w)
        return child_state._replace(axes=out_axes, ns=nsp), aux

    def __call__(self, demo: dict, aux: dict, child_state: State) -> StateReturn:
        """Apply admixture event."""
        p = self.prop_fun(demo)
        # nw = in_axes[self.child] - 1
        nw = child_state.pl.named_axes[self.child] - 1
        xw, j1, m1 = np.ogrid[(slice(None, nw + 1),) * 3]
        B = binom_pmf_safe(m1, nw, p)
        # unpacking the next expression:
        # - (H1 * B)[xw, j1, m1] = prob of j1 black balls when there are xw black balls and nw total balls
        #   and m1 total draws, and m1 is distributed binomially with probability p
        # - From setup(), H2[xw,j2,nw-m1] is as described below.
        # - the convolve_sum() operation convolves (H1*B) and H2 along the last axis:
        #   C[j,k,l+m] += sum_n (B*H1)[j,l,n] * H2[k,m,n]
        #   this says that C[j,k,u] is the probability of drawing u black balls from two urns when the total
        #   number of draws from urn 1 is binomial(p) and the total number of black balls in the two urns
        #   are j and k respectively.
        C = convolve_sum(aux["H1"] * B, aux["H2"])
        # import jax
        C = C[
            :, :, : nw + 1
        ]  # slice down to nw + 1 because we can't draw more than that.
        assert C.shape == (nw + 1,) * 3

        @pz.nx.nmap
        def f(v):
            """Apply the admixture lemma."""
            # v is the partial likelihood of the parents, with axes [parent1, parent2, child]
            parent1 = 0
            parent2 = 1
            child = 2
            return jnp.einsum(
                v, [child], C, [parent1, parent2, child], [parent1, parent2]
            )

        plp = f(child_state.pl.untag(self.child)).tag(self.parent1, self.parent2)
        return child_state._replace(pl=plp), {}


def admix_matrices(nw: Int[ScalarLike, ""]) -> dict[str, np.ndarray]:
    xw, j1, m1 = np.ogrid[(slice(None, nw + 1),) * 3]
    m2 = nw - m1
    # H1[x,j,m] = prob of j black balls when there are x black balls and nw total balls and m total draws
    H1 = np.exp(log_hypergeom(n=xw, k=j1, M=nw, N=m1))
    # H2[x,j,m] = prob of j black balls when there are x black balls and nw total balls and nw - m total draws
    H2 = np.exp(log_hypergeom(n=xw, k=j1, M=nw, N=m2))
    return {"H1": H1, "H2": H2}


def binom_pmf_safe(k, n, p):
    p_safe = jnp.where(jnp.isclose(p, 0.0) | jnp.isclose(p, 1.0), 0.5, p)
    return jnp.select(
        [jnp.isclose(p, 0.0), jnp.isclose(p, 1.0)],
        [(k == 0).astype(float), (k == n).astype(float)],
        jax.scipy.stats.binom.pmf(k, n, p_safe),
    )


def convolve_sum(A, B):
    "C[j,k,l+m] = sum_{i,n} A[i,j,l,n] * B[i,k,m,n]"
    k = B.shape[2]

    def f1(aj, bk):
        return jax.lax.conv_general_dilated(
            aj[None, None],
            bk[
                None,
                None,
                ::-1,
            ],
            (1, 1),
            ((k - 1, k - 1), (0, 0)),
        ).squeeze()

    f2 = jax.vmap(f1, (None, 0))
    f3 = jax.vmap(f2, (0, None))
    return f3(A, B)
