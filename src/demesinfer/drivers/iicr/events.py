import jax
from typing import NamedTuple

import demesinfer.events as events
import demesinfer.util as util


class State(NamedTuple):
    # p is an (d,)*n  array denoting the joint probability that each of N lineages is
    # in each of D demes.
    # c is the probability that the first coalescence event has not occured by time t.

    p: jax.Array
    pops: tuple[str]
    log_s: float
    c: float
    t: float

    def check_shape(self):
        assert p.shape[0] == 1 + len(self.pops)


@dataclass(kw_only=True)
class Lift(event.Lift):
    t0: Path
    t1: Path
    pops: set[str]

    def setup(self, state: SetupState) -> tuple[SetupState, dict]:
        # find cliques of migration populations
        G = nx.DiGraph()
        G.add_nodes_from(block)
        G.add_edges_from(migrations)
        migration_sets = [tuple(c) for c in nx.connected_components(G.to_undirected())]
        return state, dict(migration_sets=migration_sets)

    def execute(
        self,
        state: State,
        pops: set[str],
        t0: float,
        t1: float,
        params: dict,
        aux: dict,
    ) -> State:
        """Lift partial likelihood.

        Args:
            st: state just before the lifting event
            params: dict of parameters
            aux: dict of auxiliary data generated by setup

        Returns:
            State after the lifting event.
        """
        n = st.p.ndim
        d = len(state.pops)
        assert st.p.shape == (d + 1,) * n, (
            f"Expected shape {(d + 1,) * n}, got {st.p.shape}"
        )
        inds = jnp.transpose(jnp.unravel_index(jnp.arange((d + 1) ** n), (d + 1,) * n))
        counts = jax.vmap(lambda b: jnp.bincount(b, length=d + 1))(inds).reshape(
            (d + 1,) * n + (d + 1,)
        )
        C = counts * (counts - 1) / 2
        t0, t1 = [get_path(params, t.path) for t in (self.t0, self.t1)]
        u = jnp.clip(st.t, t0, t1)
        t_isin_t0_t1 = (t0 <= st.t) & (st.t < t1)

        mu = util.migration_rates(params)
        eta = util.coalescent_rates(params)

        migration_sets = set(aux["migration_sets"])  # create a copy

        if mielf.migrations == {} or self.terminal:
            # no migrations, so just lift each population to r and t1
            R = []
            for p in state.pops:
                R.append(etas[p].R(u) - etas[p].R(t0))
            # no coalescence allowed in the "untracked" deme
            R.append(0.0)
            R = jnp.array(R)
            x = C.dot(R)
            # probability of no coalescence
            log_p_nc = -x
            p0 = jnp.isclose(st.p, 0.0)
            safe_p = jnp.where(p0, 1.0, st.p)
            log_p_prime = jnp.where(p0, -jnp.inf, jnp.log(safe_p) + log_p_nc)
            log_s_prime = jnp.where(st.t < t0, 0.0, logsumexp(log_p_prime))
            p_prime = jnp.exp(log_p_prime - log_s_prime)
            e_u = etas(u)
            coal = jnp.array([1 / 2 / e_u[p] for p in state.pops])
            coal = jnp.append(coal, 0.0)
            # probability distribution conditional on no coalescence
            c_prime = jnp.where(t_isin_t0_t1, jnp.sum(p_prime * C.dot(coal)), 0.0)
            # no change to p since the lineages do not migrate
            return st._replace(
                p=p_prime,
                log_s=st.log_s + log_s_prime,
                c=st.c + c_prime,
                terminal=self.terminal,
            )

        def rate(t, y, args):
            etas, C = args
            eta = jnp.array([1 / 2 / etas[pop](t) for pop in axes])
            eta = jnp.append(eta, 0.0)
            return C.dot(eta)

        def stats(t, y, args):
            p, s = y
            p /= p.sum()
            c = jnp.sum(p * rate(t, y, args))
            return (p, c, s)

        def f(t, y, args):
            # migration matrix at time t
            etas, C = args
            M_t = M(t)
            M_t = jnp.pad(
                M_t, ((0, 1), (0, 1)), constant_values=0.0
            )  # add untracked deme
            # transition p forward in time
            p, s = y
            ds = p * rate(t, y, args)
            # multiply along each axis, equivalent of direct sum
            dp = sum(
                map(
                    lambda i: jnp.apply_along_axis(M_t.T.__matmul__, i, p),
                    range(n),
                )
            )
            # movement into coalescent state
            dp -= ds  # movement among migrant states, independent
            # jax.debug.print("p:{} s:{} dp:{} ds:{}", p, s, dp, ds, ordered=True)
            return dp, ds.sum()

        solver = dfx.Kvaerno3()
        term = dfx.ODETerm(f)
        eta_ts = jnp.concatenate([eta.t for eta in etas.values()])
        jump_ts = jnp.concatenate([M.jump_ts, eta_ts])
        jump_ts = jnp.sort(jump_ts).clip(t0, t1)
        # final_subsaveat = dfx.SubSaveAt(t1=True)
        # evolving_subsaveat = dfx.SubSaveAt(ts=[u], fn=stats)
        saveat = dfx.SaveAt(ts=[u, t1], fn=stats)
        ssc = dfx.PIDController(jump_ts=jump_ts, rtol=1e-6, atol=1e-6)
        args = (etas, C)
        y0 = (st.p, 0.0)

        res = dfx.diffeqsolve(
            term,
            solver,
            t0=t0,
            t1=t1,
            dt0=(t1 - t0) / 1000,
            args=args,
            y0=y0,
            stepsize_controller=ssc,
            max_steps=16384,
            saveat=saveat,
        )

        (_, p1), (cu, _), (su, s1) = res.ys
        p1 /= p1.sum()  # normalize to probability conditional on non-coalescence
        log_s_prime = jnp.where(st.t < t0, 0.0, jnp.log1p(-su))
        c_prime = jnp.where(t_isin_t0_t1, cu, 0.0)
        return st._replace(
            p=p1, log_s=st.log_s + log_s_prime, c=st.c + c_prime, terminal=self.terminal
        )


@dataclass(kw_only=True)
class Split1(events.Split1):
    def execute(self, state: State, params: dict, aux: dict) -> State:
        axes = state.axes
        assert self.donor in axes
        assert self.recipient in axes
        lst = list(axes)
        j = lst.index(self.donor)
        lst.pop(j)  # remove the donor from the axes
        k = lst.index(self.recipient)
        axes = tuple(lst)
        p_prime = _merge(state.p, j, k)
        return state._replace(axes=axes, p=p_prime)


@dataclass(kw_only=True)
class Split2(events.Split2):
    def execute(self, state: dict[str, State], params: dict, aux: Any) -> State:
        """Merge two populations in different event blocks.

        Args:
            st: state just before the merge event
            params: dict of parameters
            aux: dict of auxiliary data generated by setup
        """
        donor_st = state["donor_state"]
        recip_st = state["recipient_state"]
        p_prime = _product(recip_st.p, donor_st.p)
        # now want to merge the populations in donor and recip into one
        combined_axes = recip_st.axes + donor_st.axes
        j, k = [list(combined_axes).index(x) for x in (self.donor, self.recipient)]
        p_prime = _merge(p_prime, j, k)
        ca = list(combined_axes)
        ca.remove(self.donor)
        return State(
            p=p_prime,
            axes=ca,
            log_s=donor_st.log_s + recip_st.log_s,
            c=donor_st.c + recip_st.c,
            t=donor_st.t,  # t is the same for both populations
            terminal=False,
        )


@dataclass(kw_only=True)
class MigrationStart(events.MigrationStart):
    def setup(self, state: SetupState) -> SetupState:
        mig = state.migrations | {(self.source, self.dest)}
        return state._replace(migrations=mig), None

    def execute(
        self, state: dict[str, State], params: dict, aux: set[tuple[str, str]]
    ) -> State:
        # merge the two population tensors into one
        src_st = state["source_state"]
        dst_st = state["dest_state"]
        # an empty/scalar tensor represents one deme with no lineages
        p_prime = _product(src_st.p, dst_st.p)
        return State(
            p=p_prime,
            log_s=src_st.log_s + dst_st.log_s,
            c=src_st.c + dst_st.c,
            t=src_st.t,  # t is the same for both populations
            terminal=False,
        )


@dataclass(kw_only=True)
class MigrationEnd(events.MigrationStart):
    def setup(self, state: SetupState) -> SetupState:
        mig = state.migrations - {(self.source, self.dest)}
        return state._replace(migrations=mig), None


@dataclass(kw_only=True)
class Admix(events.Admix):
    def execute(self, state: State, params: dict, aux: Any) -> State:
        p_admix = self.prop_fun(params)
        # child splits into self.parent1 and self.parent2
        axes = list(state.axes)
        i = axes.index(self.child)
        axes.pop(i)
        axes.extend([self.parent1, self.parent2])
        n = len(axes)
        p_prime = _split(st.p, i, n - 2, n - 1, p_admix)
        return st._replace(p=p_prime, axes=tuple(axes))


@dataclass(kw_only=True)
class Pulse(momi3.sfs.events.Pulse):
    def execute(self, st: State, params: dict, aux: Any) -> State:
        p_pulse = self.prop_fun(params)
        axes = list(st.axes)
        i = axes.index(self.dest)
        j = axes.index(self.source)
        p_prime = _pulse(st.p, i, j, p_pulse)
        return st._replace(p=p_prime)


def _merge(p, j, k):
    "merge population j into population k"

    # this means merge tensor indices j into k along each axis
    def f(q, i):
        def g(v):
            return jnp.delete(v, j).at[k].add(v[j])

        return jnp.apply_along_axis(g, i, q)

    return reduce(f, range(p.ndim), p)


def _split(p, j, k1, k2, prob):
    "split population j into populations k1 and k2"
    if k1 > k2:
        return _split(p, j, k2, k1, 1 - prob)

    def f(q, i):
        def g(v):
            vj = v[j]
            v = jnp.delete(v, j)
            v = jnp.insert(v, k1, vj * prob)
            v = jnp.insert(v, k2, vj * (1 - prob))
            return v

        return jnp.apply_along_axis(g, i, q)

    ret = reduce(f, range(p.ndim), p)
    return ret


def _pulse(p, j, k, prob):
    "pulse population j into population k"

    def f(q, i):
        def g(v):
            return v.at[j].multiply(1 - prob).at[k].add(v[j] * prob)

        return jnp.apply_along_axis(g, i, q)

    return reduce(f, range(p.ndim), p)


def _product(p1, p2):
    # align two ndarrays for concatenation
    n = p1.ndim
    assert n == p2.ndim
    d1 = p1.shape[0] - 1
    assert p1.shape == (d1 + 1,) * n
    d2 = p2.shape[0] - 1
    assert p2.shape == (d2 + 1,) * n
    # ret = jnp.zeros((d1 + d2 + 1,) * n)
    inds = jnp.array(jnp.meshgrid(*[jnp.arange(d1 + d2 + 1)] * n, indexing="ij"))
    i1 = jnp.where(inds < d1, inds, -1)
    i2 = jnp.where((d1 <= inds) & (inds < d1 + d2), inds - d1, -1)
    p1f = p1[*i1]
    p2f = p2[*i2]
    return (p1f * p2f).reshape((d1 + d2 + 1,) * n)
