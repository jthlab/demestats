{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3739f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "\n",
    "demo = msp.Demography()\n",
    "demo.add_population(initial_size = 5000, name = \"anc\")\n",
    "demo.add_population(initial_size = 5000, name = \"P0\")\n",
    "demo.add_population(initial_size = 5000, name = \"P1\")\n",
    "demo.add_population(initial_size = 5000, name = \"P2\")\n",
    "demo.add_population(initial_size = 5000, name = \"P3\")\n",
    "demo.add_population(initial_size = 5000, name = \"P4\")\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P1\", \"P2\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P2\", \"P3\"), rate=0.001)\n",
    "demo.set_symmetric_migration_rate(populations=(\"P3\", \"P4\"), rate=0.001)\n",
    "tmp = [f\"P{i}\" for i in range(5)]\n",
    "demo.add_population_split(time = 1000, derived=tmp, ancestral=\"anc\")\n",
    "g = demo.to_demes()\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(5)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)\n",
    "\n",
    "demesdraw.tubes(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c686911",
   "metadata": {},
   "source": [
    "## The next chunk is just the fit function pasted in a code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import msprime as msp\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "import jax.random as jr\n",
    "from jax import vmap, lax \n",
    "\n",
    "from demesinfer.coal_rate import PiecewiseConstant\n",
    "from demesinfer.constr import EventTree, constraints_for\n",
    "from demesinfer.iicr import IICRCurve\n",
    "from demesinfer.loglik.arg import loglik\n",
    "\n",
    "Path = Tuple[Any, ...]\n",
    "Var = Path | Set[Path]\n",
    "Params = Mapping[Var, float]\n",
    "\n",
    "def _dict_to_vec(d: Params, keys: Sequence[Var]) -> jnp.ndarray:\n",
    "    return jnp.asarray([d[k] for k in keys], dtype=jnp.float64)\n",
    "\n",
    "def _vec_to_dict_jax(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, jnp.ndarray]:\n",
    "    return {k: v[i] for i, k in enumerate(keys)}\n",
    "\n",
    "def _vec_to_dict(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, float]:\n",
    "    return {k: float(v[i]) for i, k in enumerate(keys)}\n",
    "\n",
    "def compile(ts, subkey):\n",
    "    # using a set to pull out all unique populations that the samples can possibly belong to\n",
    "    pop_cfg = {ts.population(ts.node(n).population).metadata[\"name\"] for n in ts.samples()}\n",
    "    pop_cfg = {pop_name: 0 for pop_name in pop_cfg}\n",
    "\n",
    "    samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "    a, b = samples[0].item(0), samples[1].item(0)\n",
    "    spans = []\n",
    "    curr_t = None\n",
    "    curr_L = 0.0\n",
    "    for tree in ts.trees():\n",
    "        L = tree.interval.right - tree.interval.left\n",
    "        t = tree.tmrca(a, b)\n",
    "        if curr_t is None or t != curr_t:\n",
    "            if curr_t is not None:\n",
    "                spans.append([curr_t, curr_L])\n",
    "            curr_t = t\n",
    "            curr_L = L\n",
    "        else:\n",
    "            curr_L += L\n",
    "    spans.append([curr_t, curr_L])\n",
    "    data = jnp.asarray(spans, dtype=jnp.float64)\n",
    "    pop_cfg[ts.population(ts.node(a).population).metadata[\"name\"]] += 1\n",
    "    pop_cfg[ts.population(ts.node(b).population).metadata[\"name\"]] += 1\n",
    "    return data, pop_cfg\n",
    "\n",
    "def get_tmrca_data(ts, key, num_samples):\n",
    "    data_list = []\n",
    "    cfg_list = []\n",
    "    max_indices = []\n",
    "    for i in range(num_samples):\n",
    "        key, subkey = jr.split(key)\n",
    "        data, cfg = compile(ts, subkey)\n",
    "        data_list.append(data)\n",
    "        cfg_list.append(cfg)\n",
    "        max_indices.append(data.shape[0] - 1)\n",
    "\n",
    "    lens = jnp.array([d.shape[0] for d in data_list], dtype=jnp.int32)\n",
    "    Lmax = int(lens.max())\n",
    "    Npairs = len(data_list)\n",
    "    data_pad = jnp.full((Npairs, Lmax, 2), jnp.array([1.0, 0.0]), dtype=jnp.float64)\n",
    "\n",
    "    for i, d in enumerate(data_list):\n",
    "        data_pad = data_pad.at[i, : d.shape[0], :].set(d)\n",
    "\n",
    "    deme_names = cfg_list[0].keys()\n",
    "    D = len(deme_names)\n",
    "    cfg_mat = jnp.zeros((num_samples, D), dtype=jnp.int32)\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        for j, n in enumerate(deme_names):\n",
    "            cfg_mat = cfg_mat.at[i, j].set(cfg.get(n, 0))\n",
    "    \n",
    "    return data_pad, cfg_mat, deme_names, jnp.array(max_indices)\n",
    "\n",
    "def plot_likelihood(demo, ts, paths, vec_values, recombination_rate=1e-8, seed=1, num_samples=20, t_min=1e-8, num_t=1000, k=2):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    key = jr.PRNGKey(seed)\n",
    "    path_order: List[Var] = list(paths)\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data, max_index):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data, max_index)\n",
    "    \n",
    "    def evaluate_at_vec(vec):\n",
    "        vec_array = jnp.atleast_1d(vec)\n",
    "        # Batched over cfg_mat and all_tmrca_spans \n",
    "        batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(vec_array, cfg_mat, data_pad, max_indices)\n",
    "        return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "    # Outer vmap: Parallelize across vec_values\n",
    "    # batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "    # # 3. Compute all values (runs on GPU/TPU if available)\n",
    "    # results = batched_neg_loglik(vec_values) \n",
    "    results = lax.map(evaluate_at_vec, vec_values)\n",
    "\n",
    "    # 4. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(vec_values, results, 'r-', linewidth=2)\n",
    "    plt.xlabel(\"vec value\")\n",
    "    plt.ylabel(\"Negative Log-Likelihood\")\n",
    "    plt.title(\"Likelihood Landscape\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return results\n",
    "\n",
    "def fit(\n",
    "    demo,\n",
    "    paths: Params,\n",
    "    ts,\n",
    "    *,\n",
    "    k: int = 2,\n",
    "    n_samples: int = 10,\n",
    "    t_min: float = 1e-8,\n",
    "    # t_max: float,\n",
    "    num_t: int = 1000,\n",
    "    method: str = \"trust-constr\",\n",
    "    options: Optional[dict] = None,\n",
    "    recombination_rate: float = 1e-8,\n",
    "    sequence_length: float = 1e7,\n",
    "    mutation_rate: float = 1e-8,\n",
    "    seed: int = 1,\n",
    "    num_samples = 20,\n",
    "):\n",
    "    key = jr.PRNGKey(seed)\n",
    "    # msp_demo = msp.Demography.from_demes(demo)\n",
    "    # deme_names = [d.name for d in demo.demes]\n",
    "    # samples = {d: n_samples for d in deme_names[1:]}\n",
    "    # ts = msp.sim_mutations(\n",
    "    #     msp.sim_ancestry(\n",
    "    #         samples=samples,\n",
    "    #         demography=msp_demo,\n",
    "    #         recombination_rate=recombination_rate,\n",
    "    #         sequence_length=sequence_length,\n",
    "    #         random_seed=seed,\n",
    "    #     ),\n",
    "    #     rate=mutation_rate,\n",
    "    #     random_seed=seed + 1,\n",
    "    # )\n",
    "\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "\n",
    "    path_order: List[Var] = list(paths)\n",
    "    x0 = _dict_to_vec(paths, path_order)\n",
    "    et = EventTree(demo)\n",
    "\n",
    "    cons = constraints_for(et, *path_order)\n",
    "    linear_constraints: list[LinearConstraint] = []\n",
    "\n",
    "    Aeq, beq = cons[\"eq\"]\n",
    "    if Aeq.size:\n",
    "        linear_constraints.append(LinearConstraint(Aeq, beq, beq))\n",
    "\n",
    "    G, h = cons[\"ineq\"]\n",
    "    if G.size:\n",
    "        lower = -jnp.inf * jnp.ones_like(h)\n",
    "        linear_constraints.append(LinearConstraint(G, lower, h))\n",
    "\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data)\n",
    "    \n",
    "    @jax.value_and_grad\n",
    "    def neg_loglik(vec):\n",
    "        vec = vec\n",
    "        batched_loglik = vmap(\n",
    "        compute_loglik,\n",
    "        in_axes=(None, 0, 0))(vec, cfg_mat, data_pad)\n",
    "        \n",
    "        likelihood = jnp.sum(batched_loglik)\n",
    "\n",
    "        return -likelihood / num_samples\n",
    "\n",
    "    res = minimize(\n",
    "        fun=lambda x: float(neg_loglik(x)[0]),\n",
    "        # fun=lambda x: float(neg_loglik(x)),\n",
    "        x0=jnp.asarray(x0),\n",
    "        jac=lambda x: jnp.asarray(neg_loglik(x)[1], dtype=float),\n",
    "        method=method,\n",
    "        # bounds = [(3000. / 5000., 7000. / 5000.)],\n",
    "        constraints=linear_constraints,\n",
    "    )\n",
    "\n",
    "    return _vec_to_dict(jnp.asarray(res.x), path_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7eca74",
   "metadata": {},
   "source": [
    "## Here's how I would call on plot_likelihood over a vector of values to plot the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f5ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "paths = {\n",
    "    frozenset({\n",
    "        ('demes', 1, 'epochs', 0, 'end_size'),\n",
    "        ('demes', 1, 'epochs', 0, 'start_size'),\n",
    "    }): 4000.,\n",
    "}\n",
    "vec_values = jnp.linspace(4000, 7000, 10)\n",
    "result = plot_likelihood(g, ts, paths, vec_values, num_samples = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d9ab0",
   "metadata": {},
   "source": [
    "## Here's how I know it takes way too long to evaluate the likelihood for a *single* parameter value while averaging over 150 samples with 1000 time discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df491025",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(1)\n",
    "num_samples=150\n",
    "path_order: List[Var] = list(paths)\n",
    "data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples=num_samples)\n",
    "first_columns = data_pad[:, :, 0]\n",
    "# Compute global max (single float value)\n",
    "global_max = jnp.max(first_columns)\n",
    "t_breaks = jnp.linspace(1e-8, global_max * 2, 1000)\n",
    "rho = 1e-8\n",
    "iicr = IICRCurve(demo=g, k=2)\n",
    "iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "def compute_loglik(vec, sample_config, data, max_index):\n",
    "    # Convert sample_config (array) to dictionary of population sizes\n",
    "    ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "    \n",
    "    # Initialize params (assuming fixed for all samples)\n",
    "    params = _vec_to_dict_jax(vec, path_order)\n",
    "    \n",
    "    # Compute IICR and log-likelihood\n",
    "    c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "    eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "    return loglik(eta, rho, data, max_index)\n",
    "\n",
    "def evaluate_at_vec(vec):\n",
    "    vec_array = jnp.atleast_1d(vec)\n",
    "    # Batched over cfg_mat and all_tmrca_spans \n",
    "    batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(vec_array, cfg_mat, data_pad, max_indices)\n",
    "    return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "# Outer vmap: Parallelize across vec_values\n",
    "# batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "# # 3. Compute all values (runs on GPU/TPU if available)\n",
    "# results = batched_neg_loglik(vec_values)\n",
    "# vec_values = jnp.linspace(4000, 7000, 10) \n",
    "results = evaluate_at_vec(4000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd4830",
   "metadata": {},
   "source": [
    "## NaNs in eta bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "\n",
    "# Create demography object\n",
    "demo = msp.Demography()\n",
    "\n",
    "# Add populations\n",
    "demo.add_population(initial_size=3000, name=\"anc\")\n",
    "demo.add_population(initial_size=1000, name=\"P0\")\n",
    "demo.add_population(initial_size=1000, name=\"P1\")\n",
    "\n",
    "# Set initial migration rate\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.0001)\n",
    "\n",
    "# population growth at 500 generations\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P0\"\n",
    ")\n",
    "demo.add_population_parameters_change(\n",
    "    time=500,\n",
    "    initial_size=3000,  # Bottleneck: reduce to 1000 individuals\n",
    "    population=\"P1\"\n",
    ")\n",
    "\n",
    "# Migration rate change changed to 0.001 AFTER 500 generation (going into the past)\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P0\",\n",
    "    dest=\"P1\"\n",
    ")\n",
    "demo.add_migration_rate_change(\n",
    "    time=500,\n",
    "    rate=0.001, \n",
    "    source=\"P1\",\n",
    "    dest=\"P0\"\n",
    ")\n",
    "\n",
    "# THEN add the older events (population split at 1000)\n",
    "demo.add_population_split(time=1000, derived=[\"P0\", \"P1\"], ancestral=\"anc\")\n",
    "\n",
    "# Visualize the demography\n",
    "g = demo.to_demes()\n",
    "demesdraw.tubes(g)\n",
    "\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(2)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e8, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2fa7f",
   "metadata": {},
   "source": [
    "## copy pasting fit function into next code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ebd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example implementation of a fit function for parameter inference.\n",
    "# This is intended for tutorial use only. We do not take responsibility for any bugs or issues in this code.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, List, Mapping, Optional, Sequence, Set, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import msprime as msp\n",
    "from scipy.optimize import LinearConstraint, minimize\n",
    "import jax.random as jr\n",
    "from jax import vmap, lax \n",
    "\n",
    "from demesinfer.coal_rate import PiecewiseConstant\n",
    "from demesinfer.constr import EventTree, constraints_for\n",
    "from demesinfer.iicr import IICRCurve\n",
    "from demesinfer.loglik.arg import loglik\n",
    "\n",
    "Path = Tuple[Any, ...]\n",
    "Var = Path | Set[Path]\n",
    "Params = Mapping[Var, float]\n",
    "\n",
    "def _dict_to_vec(d: Params, keys: Sequence[Var]) -> jnp.ndarray:\n",
    "    return jnp.asarray([d[k] for k in keys], dtype=jnp.float64)\n",
    "\n",
    "def _vec_to_dict_jax(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, jnp.ndarray]:\n",
    "    return {k: v[i] for i, k in enumerate(keys)}\n",
    "\n",
    "def _vec_to_dict(v: jnp.ndarray, keys: Sequence[Var]) -> Dict[Var, float]:\n",
    "    return {k: float(v[i]) for i, k in enumerate(keys)}\n",
    "\n",
    "def compile(ts, subkey):\n",
    "    # using a set to pull out all unique populations that the samples can possibly belong to\n",
    "    pop_cfg = {ts.population(ts.node(n).population).metadata[\"name\"] for n in ts.samples()}\n",
    "    pop_cfg = {pop_name: 0 for pop_name in pop_cfg}\n",
    "\n",
    "    samples = jax.random.choice(subkey, ts.num_samples, shape=(2,), replace=False)\n",
    "    a, b = samples[0].item(0), samples[1].item(0)\n",
    "    spans = []\n",
    "    curr_t = None\n",
    "    curr_L = 0.0\n",
    "    for tree in ts.trees():\n",
    "        L = tree.interval.right - tree.interval.left\n",
    "        t = tree.tmrca(a, b)\n",
    "        if curr_t is None or t != curr_t:\n",
    "            if curr_t is not None:\n",
    "                spans.append([curr_t, curr_L])\n",
    "            curr_t = t\n",
    "            curr_L = L\n",
    "        else:\n",
    "            curr_L += L\n",
    "    spans.append([curr_t, curr_L])\n",
    "    data = jnp.asarray(spans, dtype=jnp.float64)\n",
    "    pop_cfg[ts.population(ts.node(a).population).metadata[\"name\"]] += 1\n",
    "    pop_cfg[ts.population(ts.node(b).population).metadata[\"name\"]] += 1\n",
    "    return data, pop_cfg\n",
    "\n",
    "def get_tmrca_data(ts, key, num_samples):\n",
    "    data_list = []\n",
    "    cfg_list = []\n",
    "    max_indices = []\n",
    "    for i in range(num_samples):\n",
    "        key, subkey = jr.split(key)\n",
    "        data, cfg = compile(ts, subkey)\n",
    "        data_list.append(data)\n",
    "        cfg_list.append(cfg)\n",
    "        max_indices.append(data.shape[0] - 1)\n",
    "\n",
    "    lens = jnp.array([d.shape[0] for d in data_list], dtype=jnp.int32)\n",
    "    Lmax = int(lens.max())\n",
    "    Npairs = len(data_list)\n",
    "    data_pad = jnp.full((Npairs, Lmax, 2), jnp.array([1.0, 0.0]), dtype=jnp.float64)\n",
    "\n",
    "    for i, d in enumerate(data_list):\n",
    "        data_pad = data_pad.at[i, : d.shape[0], :].set(d)\n",
    "\n",
    "    deme_names = cfg_list[0].keys()\n",
    "    D = len(deme_names)\n",
    "    cfg_mat = jnp.zeros((num_samples, D), dtype=jnp.int32)\n",
    "    for i, cfg in enumerate(cfg_list):\n",
    "        for j, n in enumerate(deme_names):\n",
    "            cfg_mat = cfg_mat.at[i, j].set(cfg.get(n, 0))\n",
    "\n",
    "    unique_cfg = jnp.unique(cfg_mat, axis=0)\n",
    "\n",
    "    # Find matching indices\n",
    "    def find_matching_index(row, unique_arrays):\n",
    "        matches = jnp.all(row == unique_arrays, axis=1)\n",
    "        return jnp.where(matches)[0][0]\n",
    "\n",
    "    # Vectorize over all rows in `arr`\n",
    "    matching_indices = jnp.array([find_matching_index(row, unique_cfg) for row in cfg_mat])\n",
    "    \n",
    "    return data_pad, cfg_mat, deme_names, jnp.array(max_indices), unique_cfg, matching_indices\n",
    "\n",
    "def plot_likelihood(demo, ts, paths, vec_values, recombination_rate=1e-8, seed=1, num_samples=20, t_min=1e-8, num_t=1000, k=2):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    key = jr.PRNGKey(seed)\n",
    "    path_order: List[Var] = list(paths)\n",
    "    data_pad, cfg_mat, deme_names, max_indices, unique_cfg, matching_indices = get_tmrca_data(ts, key, num_samples)\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    print(global_max)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(c_map, c_index, data, max_index):\n",
    "        c = c_map[c_index]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data, max_index)\n",
    "    \n",
    "    def evaluate_at_vec(vec):\n",
    "        vec_array = jnp.atleast_1d(vec)\n",
    "        params = _vec_to_dict_jax(vec_array, path_order)\n",
    "\n",
    "        def compute_c(sample_config):\n",
    "            # Convert sample_config (array) to dictionary of population sizes\n",
    "            ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "            \n",
    "            # Compute IICR and log-likelihood\n",
    "            c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "            return c\n",
    "        c_map = vmap(compute_c, in_axes=(0))(unique_cfg)\n",
    "        # c_map = jax.vmap(lambda cfg: iicr_call(params=params, t=t_breaks, num_samples=dict(zip(deme_names, cfg)))[\"c\"])(\n",
    "        #     jnp.array(unique_cfg)\n",
    "        # )\n",
    "        \n",
    "        # Batched over cfg_mat and all_tmrca_spans \n",
    "        batched_loglik = vmap(compute_loglik, in_axes=(None, 0, 0, 0))(c_map, matching_indices, data_pad, max_indices)\n",
    "        return -jnp.sum(batched_loglik) / num_samples  # Same as original neg_loglik\n",
    "\n",
    "    # Outer vmap: Parallelize across vec_values\n",
    "    batched_neg_loglik = vmap(evaluate_at_vec)  # in_axes=0 is default\n",
    "\n",
    "    # 3. Compute all values (runs on GPU/TPU if available)\n",
    "    results = batched_neg_loglik(vec_values) \n",
    "    # results = lax.map(evaluate_at_vec, vec_values)\n",
    "\n",
    "    # 4. Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(vec_values, results, 'r-', linewidth=2)\n",
    "    plt.xlabel(\"vec value\")\n",
    "    plt.ylabel(\"Negative Log-Likelihood\")\n",
    "    plt.title(\"Likelihood Landscape\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return results\n",
    "\n",
    "def fit(\n",
    "    demo,\n",
    "    paths: Params,\n",
    "    ts,\n",
    "    *,\n",
    "    k: int = 2,\n",
    "    n_samples: int = 10,\n",
    "    t_min: float = 1e-8,\n",
    "    # t_max: float,\n",
    "    num_t: int = 1000,\n",
    "    method: str = \"trust-constr\",\n",
    "    options: Optional[dict] = None,\n",
    "    recombination_rate: float = 1e-8,\n",
    "    sequence_length: float = 1e7,\n",
    "    mutation_rate: float = 1e-8,\n",
    "    seed: int = 1,\n",
    "    num_samples = 20,\n",
    "):\n",
    "    key = jr.PRNGKey(seed)\n",
    "    # msp_demo = msp.Demography.from_demes(demo)\n",
    "    # deme_names = [d.name for d in demo.demes]\n",
    "    # samples = {d: n_samples for d in deme_names[1:]}\n",
    "    # ts = msp.sim_mutations(\n",
    "    #     msp.sim_ancestry(\n",
    "    #         samples=samples,\n",
    "    #         demography=msp_demo,\n",
    "    #         recombination_rate=recombination_rate,\n",
    "    #         sequence_length=sequence_length,\n",
    "    #         random_seed=seed,\n",
    "    #     ),\n",
    "    #     rate=mutation_rate,\n",
    "    #     random_seed=seed + 1,\n",
    "    # )\n",
    "\n",
    "    data_pad, cfg_mat, deme_names, max_indices = get_tmrca_data(ts, key, num_samples)\n",
    "\n",
    "    path_order: List[Var] = list(paths)\n",
    "    x0 = _dict_to_vec(paths, path_order)\n",
    "    et = EventTree(demo)\n",
    "\n",
    "    cons = constraints_for(et, *path_order)\n",
    "    linear_constraints: list[LinearConstraint] = []\n",
    "\n",
    "    Aeq, beq = cons[\"eq\"]\n",
    "    if Aeq.size:\n",
    "        linear_constraints.append(LinearConstraint(Aeq, beq, beq))\n",
    "\n",
    "    G, h = cons[\"ineq\"]\n",
    "    if G.size:\n",
    "        lower = -jnp.inf * jnp.ones_like(h)\n",
    "        linear_constraints.append(LinearConstraint(G, lower, h))\n",
    "\n",
    "    first_columns = data_pad[:, :, 0]\n",
    "    # Compute global max (single float value)\n",
    "    global_max = jnp.max(first_columns)\n",
    "    t_breaks = jnp.linspace(t_min, global_max * 2, num_t)\n",
    "    rho = recombination_rate\n",
    "    iicr = IICRCurve(demo=demo, k=k)\n",
    "    iicr_call = jax.jit(iicr.__call__)\n",
    "\n",
    "    def compute_loglik(vec, sample_config, data):\n",
    "        # Convert sample_config (array) to dictionary of population sizes\n",
    "        ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "        \n",
    "        # Initialize params (assuming fixed for all samples)\n",
    "        params = _vec_to_dict_jax(vec, path_order)\n",
    "        \n",
    "        # Compute IICR and log-likelihood\n",
    "        c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "        eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "        return loglik(eta, rho, data)\n",
    "    \n",
    "    @jax.value_and_grad\n",
    "    def neg_loglik(vec):\n",
    "        vec = vec\n",
    "        batched_loglik = vmap(\n",
    "        compute_loglik,\n",
    "        in_axes=(None, 0, 0))(vec, cfg_mat, data_pad)\n",
    "        \n",
    "        likelihood = jnp.sum(batched_loglik)\n",
    "\n",
    "        return -likelihood / num_samples\n",
    "\n",
    "    res = minimize(\n",
    "        fun=lambda x: float(neg_loglik(x)[0]),\n",
    "        # fun=lambda x: float(neg_loglik(x)),\n",
    "        x0=jnp.asarray(x0),\n",
    "        jac=lambda x: jnp.asarray(neg_loglik(x)[1], dtype=float),\n",
    "        method=method,\n",
    "        # bounds = [(3000. / 5000., 7000. / 5000.)],\n",
    "        constraints=linear_constraints,\n",
    "    )\n",
    "\n",
    "    return _vec_to_dict(jnp.asarray(res.x), path_order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14446361",
   "metadata": {},
   "source": [
    "## Here is the NaN error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f80c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "paths = {\n",
    "    frozenset({('demes', 2, 'start_time'), ('demes', 0, 'epochs', 0, 'end_time'), ('demes', 1, 'start_time'), ('migrations', 0, 'start_time'), ('migrations', 1, 'start_time')}): 2000.,\n",
    "}\n",
    "vec_values = jnp.linspace(500, 1500, 20)\n",
    "\n",
    "key = jr.PRNGKey(1)\n",
    "path_order: List[Var] = list(paths)\n",
    "data_pad, cfg_mat, deme_names, max_indices, unique_cfg, matching_indices = get_tmrca_data(ts, key, num_samples=5)\n",
    "first_columns = data_pad[:, :, 0]\n",
    "# Compute global max (single float value)\n",
    "global_max = jnp.max(first_columns)\n",
    "print(global_max)\n",
    "t_breaks = jnp.linspace(1e-8, global_max * 2, 1000)\n",
    "rho = 1e-8\n",
    "iicr = IICRCurve(demo=g, k=2)\n",
    "iicr_call = jax.jit(iicr.__call__)\n",
    "params = _vec_to_dict_jax(jnp.array([vec_values[0]]), path_order)\n",
    "i = 0\n",
    "data = data_pad[i]\n",
    "sample_config = cfg_mat[i]\n",
    "max_index = max_indices[i]\n",
    "# Convert sample_config (array) to dictionary of population sizes\n",
    "ns = {name: sample_config[i] for i, name in enumerate(deme_names)}\n",
    "\n",
    "# Compute IICR and log-likelihood\n",
    "c = iicr_call(params=params, t=t_breaks, num_samples=ns)[\"c\"]\n",
    "eta = PiecewiseConstant(c=c, t=t_breaks)\n",
    "loglik(eta, rho, data, max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f1efd",
   "metadata": {},
   "source": [
    "## Here is the params type error, the iicr can be called on with frozenset in the dictionary but esfs cannot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48082a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import msprime as msp\n",
    "import demes\n",
    "import demesdraw\n",
    "import demes\n",
    "from demesinfer.sfs import ExpectedSFS\n",
    "\n",
    "demo = msp.Demography()\n",
    "demo.add_population(initial_size = 5000, name = \"anc\")\n",
    "demo.add_population(initial_size = 5000, name = \"P0\")\n",
    "demo.add_population(initial_size = 5000, name = \"P1\")\n",
    "demo.set_symmetric_migration_rate(populations=(\"P0\", \"P1\"), rate=0.001)\n",
    "tmp = [f\"P{i}\" for i in range(2)]\n",
    "demo.add_population_split(time = 1000, derived=tmp, ancestral=\"anc\")\n",
    "g = demo.to_demes()\n",
    "sample_size = 10\n",
    "samples = {f\"P{i}\": sample_size for i in range(2)}\n",
    "anc = msp.sim_ancestry(samples=samples, demography=demo, recombination_rate=1e-8, sequence_length=1e7, random_seed = 12)\n",
    "ts = msp.sim_mutations(anc, rate=1e-8, random_seed = 12)\n",
    "\n",
    "samples = {f\"P{i}\": 20 for i in range(2)}\n",
    "esfs = ExpectedSFS(g, num_samples=samples)\n",
    "# e1 = esfs(params = {('migrations', 0, 'rate'): 0.005} )\n",
    "e1 = esfs(params = {frozenset({\n",
    "        ('demes', 0, 'epochs', 0, 'end_size'),\n",
    "        ('demes', 0, 'epochs', 0, 'start_size'),\n",
    "    }): 7000.} )\n",
    "afs = ts.allele_frequency_spectrum(sample_sets=[ts.samples([1]), ts.samples([2])], span_normalise=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
