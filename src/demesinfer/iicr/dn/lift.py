import itertools
import math
from functools import partial, reduce
from typing import NamedTuple

import diffrax as dfx
import equinox as eqx
import jax
import jax.numpy as jnp
import numpy as np
import sparse
from expm_unif import expm_multiply
from jax.experimental.sparse import BCOO
from jax.scipy.special import gammaln
from jaxtyping import Array, Float, Int, Scalar, ScalarLike
from loguru import logger

import demesinfer.util as util
from demesinfer.bounded_solver import BoundedSolver
from demesinfer.path import Path

from .. import lift
from .interp import DfxInterp, ExpmDnInterp, PanmicticDnInterp
from .state import SetupState
from .state import StateDn as State


def setup(
    state: SetupState,
    t0i: Int[ScalarLike, ""],
    t1i: Int[ScalarLike, ""],
    terminal: bool,
    constant: bool,
    migrations: list[tuple[str, str]],
    aux: dict,
    demo: dict,
) -> tuple[SetupState, dict]:
    aux_out = {}
    if constant and migrations:
        I = sparse.eye(state.d + 1)
        Qm = {}
        for pop1, pop2 in migrations:
            M = np.zeros((state.d + 1, state.d + 1))
            i, j = [state.pops.index(p) for p in (pop1, pop2)]
            M[i, j] = 1.0
            M[i, i] = -1.0
            M = sparse.COO(M)
            Qs = []
            for k in range(state.n):
                kp = [I] * state.n
                kp[k] = M
                Qs.append(reduce(sparse.kron, kp))
            Q = sum(Qs)
            Q = BCOO.from_scipy_sparse(Q.to_scipy_sparse())
            Qm[(pop1, pop2)] = Q
        aux_out["Qm"] = Qm
    return state, aux_out


def _lift_expm(
    state: State,
    t0: ScalarLike,
    t1: ScalarLike,
    demo: dict,
    aux: dict,
) -> tuple[State, dict]:
    mu = partial(util.migration_rate, demo)
    C = state.C
    t_mid = (t0 + t1) / 2.0  # midpoint for rates
    R = state.coal_rate(t_mid, demo)

    # migration matrix at time t
    Qms = [mu(dest, src, t_mid) * Q for (dest, src), Q in aux["Qm"].items()]
    Qm = sum(Qms[1:], Qms[0])

    # coalescence
    data = -R.reshape(-1)
    (s,) = data.shape
    assert s == (state.d + 1) ** state.n
    i = jnp.arange(s, dtype=Qm.indices.dtype)
    indices = jnp.stack([i, i], axis=1)
    Qc = BCOO((data, indices), shape=(s, s))

    # rate matrix
    Q_2d = Qm + Qc

    if Q_2d.size < 1000:
        Q_2d = Q_2d.todense()
    ts = jnp.linspace(t0, t1, 100)
    p_dn = state.p
    res = expm_multiply(Q_2d.T, ts - t0, p_dn.reshape(-1)).reshape(-1, *(p_dn.shape))
    p_prime = res[-1]
    p_nc = p_prime.sum()
    p1 = p_prime / p_nc  # normalize to probability conditional on non-coales
    f = ExpmDnInterp(
        state=state,
        t0=t0,
        t1=t1,
        ts=ts,
        ps=res,
    )
    state = State(
        p=p1,
        log_s=state.log_s + jnp.log(p_nc),
        pops=state.pops,
    )
    return state, {"interp": f}


def _ode(t, y, args):
    state, demo, C = args
    n = state.p.ndim
    mu = partial(util.migration_rate, demo)

    # migration matrix at time t
    M_t = jnp.array([[mu(dest, src, t) for dest in state.pops] for src in state.pops])
    M_t = jnp.pad(M_t, ((0, 1), (0, 1)), constant_values=0.0)  # add untracked deme
    M_t = M_t - jnp.diag(M_t.sum(axis=1))  # make it a stochastic matrix
    # transition p forward in time
    p, s = y
    ds = p * state.coal_rate(t, demo)
    # multiply along each axis, equivalent of direct sum
    dp = sum(
        map(
            lambda i: jnp.apply_along_axis(M_t.T.__matmul__, i, p),
            range(n),
        )
    )
    # movement into coalescent state
    dp -= ds  # movement among migrant states, independent
    return dp, ds.sum()


def _lift_ode(
    state: State,
    t0: ScalarLike,
    t1: ScalarLike,
    demo: dict,
    aux: dict,
) -> tuple[State, dict]:
    """Lift partial likelihood.

    Args:
        st: state just before the lifting event
        demo: dict of parameters
        aux: dict of auxiliary data generated by setup

    Returns:
        State after the lifting event.
    """
    aux = aux or {}
    etas = util.coalescent_rates(demo)
    eta_ts = jnp.concatenate([eta.t[:-1] for eta in etas.values()])
    mu_ts = jnp.array(
        [m.get(x, t0) for m in demo["migrations"] for x in ("start_time", "end_time")]
    )
    jump_ts = jnp.concatenate([eta_ts, mu_ts])
    jump_ts = jnp.sort(jump_ts)
    saveat = dfx.SaveAt(dense=True, t1=True)
    # FIXME using jump_ts causes nans to be returned
    ssc = dfx.PIDController(rtol=1e-8, atol=1e-8, jump_ts=jump_ts)
    y0 = (state.p, 0.0)

    term = dfx.ODETerm(_ode)

    def oob_fn(y):
        p, s = y
        eps = 1e-8
        return jnp.any(p < -eps) | jnp.any(p > 1 + eps) | (s < -eps) | (s > 1 + eps)

    C = state.C
    args = (state, demo, C)
    solver = BoundedSolver(oob_fn=oob_fn)

    # if f has error, this will throw more comprehensibly than doing it inside of diffeqsolve
    _ = _ode(t0, y0, args)

    sol = dfx.diffeqsolve(
        term,
        solver,
        t0=t0,
        t1=t1,
        dt0=(t1 - t0) / 100.0,
        args=args,
        y0=y0,
        stepsize_controller=ssc,
        saveat=saveat,
        max_steps=4096,
    )
    p1 = sol.ys[0][0]
    s1 = sol.ys[1][0]
    p1 = p1 / p1.sum()  # normalize to probability conditional on non-coalescence

    # interp interpolates from the "bottom" state up to t \in [t0, t1]
    interp = DfxInterp(sol=sol, state=state, t0=t0, t1=t1, jump_ts=jump_ts)

    # state update come *after* interp is created
    s1 = jnp.clip(s1, a_min=0.0, a_max=1.0 - 1e-7)  # avoid log(0)
    state = State(
        p=p1,
        log_s=state.log_s + jnp.log1p(-s1),
        pops=state.pops,
    )

    return state, {"interp": interp}


execute = partial(
    lift.execute,
    PanmicticInterp=PanmicticDnInterp,
    lift_ode=_lift_ode,
    lift_expm=_lift_expm,
)
